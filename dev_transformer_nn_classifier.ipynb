{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 49748,\n",
      "  \"iopub_port\": 49749,\n",
      "  \"stdin_port\": 49750,\n",
      "  \"control_port\": 49752,\n",
      "  \"hb_port\": 49751,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"d921f901-03c5468d5a24e4101a265c6b\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-04fdfb77-9818-490e-a512-4dbb224d5443.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible models\n",
    "\n",
    "`bert-base-multilingual-cased`: (New, recommended) 12-layer, 768-hidden, 12-heads, 110M parameters. Trained on cased text in the top 104 languages with the largest Wikipedias\n",
    "\n",
    "`xlm-mlm-100-1280`: 16-layer, 1280-hidden, 16-heads XLM model trained with MLM (Masked Language Modeling) on 100 languages.\n",
    "\n",
    "`distilbert-base-multilingual-cased`: 6-layer, 768-hidden, 12-heads, 134M parameters The multilingual DistilBERT model distilled from the Multilingual BERT model bert-base-multilingual-cased checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = sys.argv[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from evaluation import  evaluate #, MetricsReporterCallback,\n",
    "from utils import build_model_name, convert_flags_to_dict, define_nn_flags\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "# from ray.tune.integration.keras import TuneReporterCallback\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.suggest import Repeater\n",
    "from hyperopt import hp\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BASE_DIR = os.path.expanduser(\"~\")     # this will point to the user's home\n",
    "TRAIN_DIR = \"ray_results\"\n",
    "\n",
    "FLAGS = define_nn_flags(tf.compat.v1.flags, BASE_DIR, TRAIN_DIR)\n",
    "FLAGS.layers = [int(i) for i in FLAGS.layers]\n",
    "\n",
    "_config = convert_flags_to_dict(FLAGS)\n",
    "_config[\"codes\"] = (['DE', 'GA', 'HI', 'PT', 'ZH']\n",
    "                    if FLAGS.language_code is 'all' else [FLAGS.language_code])\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(config):\n",
    "\n",
    "    model_name = build_model_name(config)\n",
    "\n",
    "    with open('{}/data/{}.embdata.pkl'.format(cwd, config[\"bert_type\"]),\n",
    "              'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    x_train = np.concatenate(\n",
    "        [data[code]['x_train'] for code in _config[\"codes\"]], axis=0)\n",
    "    y_train = np.concatenate(\n",
    "        [data[code]['y_train'] for code in _config[\"codes\"]], axis=0)\n",
    "    print(x_train.shape, y_train.shape)\n",
    "\n",
    "    x_dev = np.concatenate([data[code]['x_dev'] for code in _config[\"codes\"]],\n",
    "                           axis=0)\n",
    "    y_dev = np.concatenate([data[code]['y_dev'] for code in _config[\"codes\"]],\n",
    "                           axis=0)\n",
    "    print(x_dev.shape, y_dev.shape)\n",
    "\n",
    "    del data\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "                                                      y_train,\n",
    "                                                      test_size=0.15,\n",
    "                                                      random_state=SEED)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    layer_config = ([config[\"layer_size\"]] * config[\"nlayers\"]\n",
    "                    if config[\"nlayers\"] > 0 and config[\"layer_size\"] > 0\n",
    "                    else config[\"layers\"])\n",
    "\n",
    "    # Dense layers\n",
    "    for i, layer_size in enumerate(layer_config):\n",
    "        if i == 0:\n",
    "            dense_layer = tf.keras.layers.Dense(\n",
    "                layer_size,\n",
    "                input_shape=(x_train.shape[-1],),\n",
    "                activation=config[\"hidden_activation\"])\n",
    "        else:\n",
    "            dense_layer = tf.keras.layers.Dense(\n",
    "                layer_size, activation=config[\"hidden_activation\"])\n",
    "        model.add(dense_layer)\n",
    "        model.add(tf.keras.layers.Dropout(config[\"dropout\"]))\n",
    "\n",
    "    if config[\"output_size\"] == 1:\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    else:\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                2,\n",
    "                activation=config[\"output_activation\"],\n",
    "            ))\n",
    "\n",
    "    if config[\"optimizer\"] == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam\n",
    "    elif config[\"optimizer\"] == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD\n",
    "\n",
    "    # compiling model\n",
    "    model.compile(loss=config[\"loss_function\"],\n",
    "                  optimizer=optimizer(learning_rate=config[\"learning_rate\"],\n",
    "                                      clipnorm=config[\"clipnorm\"]),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    class_weights = None\n",
    "    if config[\"weighted_loss\"]:\n",
    "        weights = class_weight.compute_class_weight('balanced',\n",
    "                                                    np.unique(y_train),\n",
    "                                                    y_train.reshape(-1))\n",
    "        class_weights = {}\n",
    "\n",
    "        for i in range(weights.shape[0]):\n",
    "            class_weights[i] = weights[i]\n",
    "\n",
    "    print('Class weights: {}'.format(class_weights))\n",
    "\n",
    "    # do this check again vecause we need y_train to be 1-D for class weights\n",
    "    if config[\"output_size\"] > 1:\n",
    "        y_train = tf.keras.utils.to_categorical(y_train)\n",
    "        y_val = tf.keras.utils.to_categorical(y_val)\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(config[\"train_dir\"] +\n",
    "                                                    model_name,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [checkpoint]\n",
    "\n",
    "    if config[\"tune\"]:\n",
    "        callbacks.append(\n",
    "            MetricsReporterCallback(custom_validation_data=(x_val, y_val)))\n",
    "\n",
    "    if config[\"early_stop_patience\"] > 0:\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            min_delta=config[\"early_stop_delta\"],\n",
    "            patience=config[\"early_stop_patience\"])\n",
    "        callbacks.append(early_stop)\n",
    "\n",
    "    if config[\"log_tensorboard\"]:\n",
    "        tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=config[\"train_dir\"] + '/logs')\n",
    "        callbacks.append(tensorboard)\n",
    "\n",
    "    def lr_scheduler(epoch, lr):     # pylint: disable=C0103\n",
    "        lr_decay = config[\"lr_decay\"]**max(epoch - config[\"start_decay\"], 0.0)\n",
    "        return lr * lr_decay\n",
    "\n",
    "    if config[\"start_decay\"] > 0:\n",
    "        lrate = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "        callbacks.append(lrate)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(x_train,\n",
    "              y_train,\n",
    "              class_weight=class_weights,\n",
    "              batch_size=config[\"batch_size\"],\n",
    "              epochs=config[\"max_epochs\"],\n",
    "              callbacks=callbacks,\n",
    "              verbose=2,\n",
    "              validation_data=(x_val, y_val))\n",
    "\n",
    "    # #####\n",
    "    # Evaluation time\n",
    "    #\n",
    "    evaluate(model, test_data=(x_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"dropout\": hp.uniform(\"dropout\", 0.0, 0.9),\n",
    "    \"max_epochs\": hp.choice(\"max_epochs\", [10, 20, 30, 50]),\n",
    "    \"early_stop_delta\": hp.choice(\"early_stop_delta\", [0.001, 0.0001]),\n",
    "    \"early_stop_patience\": hp.choice(\"early_stop_patience\", [10, 20]),\n",
    "    \"hidden_activation\": hp.choice(\"hidden_activation\", ['tanh', 'relu', 'elu', 'selu']),\n",
    "    \"output_activation\": hp.choice(\"output_activation\", ['sigmoid', 'softmax']),\n",
    "    \"clipnorm\": hp.choice(\"clipnorm\", [0.5, 1.0, 2.5, 5.0, 10.0]),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(1e-4), np.log(1e-0)),\n",
    "    \"batch_size\": hp.choice(\"batch_size\", [20, 24, 32, 64, 128]),\n",
    "    \"nlayers\": hp.randint('nlayers', 1, 5) * 1,\n",
    "    \"layer_size\": hp.randint('layer_size', 1, 101) * 10,\n",
    "}\n",
    "\n",
    "_config.update({\n",
    "    \"hidden_activation\": 'relu',\n",
    "    \"optimizer\": 'adam',\n",
    "    \"threads\": 1,\n",
    "    \"output_size\": 2,\n",
    "    \"num_samples\": 500,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MetricsReporterCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Tune Callback for Keras.\"\"\"\n",
    "\n",
    "    def __init__(self, reporter=None, freq=\"epoch\", logs=None, custom_validation_data=None):\n",
    "        \"\"\"Initializer.\n",
    "\n",
    "        Args:\n",
    "            freq (str): Sets the frequency of reporting intermediate results.\n",
    "                One of [\"batch\", \"epoch\"].\n",
    "        \"\"\"\n",
    "        assert custom_validation_data, \"validation_data should not be None\"\n",
    "        self.custom_validation_data = custom_validation_data\n",
    "        self.iteration = 0\n",
    "        logs = logs or {}\n",
    "        # if freq not in [\"batch\", \"epoch\"]:\n",
    "        #     raise ValueError(\"{} not supported as a frequency.\".format(freq))\n",
    "        self.freq = \"epoch\"\n",
    "        super(MetricsReporterCallback, self).__init__()\n",
    "        self._results = None\n",
    "        self._batch_count = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        # from ray import tune\n",
    "        # logs = logs or {}\n",
    "\n",
    "        logs = self._update_logs(logs, predict=self.iteration == 0)\n",
    "\n",
    "        if not self.freq == \"batch\":\n",
    "            return\n",
    "        self.iteration += 1\n",
    "        for metric in list(logs):\n",
    "            if \"loss\" in metric and \"neg_\" not in metric:\n",
    "                logs[\"neg_\" + metric] = -logs[metric]\n",
    "        if \"acc\" in logs:\n",
    "            tune.report(keras_info=logs, mean_accuracy=logs[\"acc\"])\n",
    "        else:\n",
    "            tune.report(keras_info=logs, mean_accuracy=logs.get(\"accuracy\"))\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "\n",
    "        print('Updating metrics')\n",
    "        val_predict = (np.asarray(\n",
    "            self.model.predict(self.custom_validation_data[0]))).round()\n",
    "\n",
    "        self._results = classification_report(\n",
    "            self.custom_validation_data[1], val_predict, output_dict=True)\n",
    "\n",
    "        logs = self._update_logs(logs or {})\n",
    "\n",
    "        if not self.freq == \"epoch\":\n",
    "            return\n",
    "        self.iteration += 1\n",
    "        for metric in list(logs):\n",
    "            if \"loss\" in metric and \"neg_\" not in metric:\n",
    "                logs[\"neg_\" + metric] = -logs[metric]\n",
    "        if \"acc\" in logs:\n",
    "            tune.track.log(keras_info=logs, mean_accuracy=logs[\"acc\"])\n",
    "        else:\n",
    "            tune.track.log(keras_info=logs, mean_accuracy=logs.get(\"accuracy\"))\n",
    "\n",
    "    def _update_logs(self, logs, predict=True):\n",
    "\n",
    "        if self._results is None:\n",
    "\n",
    "            logs.update({\n",
    "                # \"accuracy\": 0.0accuracy\"],\n",
    "                \"label0_precision\": 0.00,\n",
    "                \"label0_recall\": 0.00,\n",
    "                \"label0_f1_score\": 0.00,\n",
    "                \"label0_support\": 0.00,\n",
    "                \"label1_precision\": 0.00,\n",
    "                \"label1_recall\": 0.0,\n",
    "                \"label1_f1_score\": 0.0,\n",
    "                \"f1_score\": 0.0,\n",
    "                \"label1_support\": 0.0,\n",
    "                \"macro_precision\": 0.0,\n",
    "                \"macro_recall\": 0.0,\n",
    "                \"macro_f1_score\": 0.0,\n",
    "                \"macro_support\": 0.0,\n",
    "                \"weighted_precision\": 0.0,\n",
    "                \"weighted_recall\": 0.0,\n",
    "                \"weighted_f1_score\": 0.0,\n",
    "                \"weighted_support\": 0.0})\n",
    "        else:\n",
    "\n",
    "            logs.update({\n",
    "                # \"accuracy\" :self._results[\"accuracy\"],\n",
    "                \"label0_precision\" :self._results[\"0\"][\"precision\"],\n",
    "                \"label0_recall\" :self._results[\"0\"][\"recall\"],\n",
    "                \"label0_f1_score\" :self._results[\"0\"][\"f1-score\"],\n",
    "                \"label0_support\" :self._results[\"0\"][\"support\"],\n",
    "                \"label1_precision\" :self._results[\"1\"][\"precision\"],\n",
    "                \"label1_recall\" :self._results[\"1\"][\"recall\"],\n",
    "                \"label1_f1_score\" :self._results[\"1\"][\"f1-score\"],\n",
    "                \"f1_score\" :self._results[\"1\"][\"f1-score\"],\n",
    "                \"label1_support\" :self._results[\"1\"][\"support\"],\n",
    "                \"macro_precision\" :self._results[\"macro avg\"][\"precision\"],\n",
    "                \"macro_recall\" :self._results[\"macro avg\"][\"recall\"],\n",
    "                \"macro_f1_score\" :self._results[\"macro avg\"][\"f1-score\"],\n",
    "                \"macro_support\" :self._results[\"macro avg\"][\"support\"],\n",
    "                \"weighted_precision\" :self._results[\"weighted avg\"][\"precision\"],\n",
    "                \"weighted_recall\" :self._results[\"weighted avg\"][\"recall\"],\n",
    "                \"weighted_f1_score\" :self._results[\"weighted avg\"][\"f1-score\"],\n",
    "                \"weighted_support\" :self._results[\"weighted avg\"][\"support\"]})\n",
    "\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-29 18:57:43,832\tINFO resource_spec.py:212 -- Starting Ray with 2.88 GiB memory available for workers and up to 1.46 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-05-29 18:57:44,119\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 320.000: None | Iter 80.000: None | Iter 20.000: None<br>Resources requested: 1/2 CPUs, 0/0 GPUs, 0.0/2.88 GiB heap, 0.0/0.98 GiB objects<br>Result logdir: /Users/gian/ray_results/tune-nn-bert-classifier<br>Number of trials: 90 (89 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  clipnorm</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  early_stop_delta</th><th style=\"text-align: right;\">  early_stop_patience</th><th>hidden_activation  </th><th style=\"text-align: right;\">  layer_size</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_epochs</th><th style=\"text-align: right;\">  nlayers</th><th>output_activation  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_6cdb5e42</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">       5  </td><td style=\"text-align: right;\">0.626338 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>relu               </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">    0.0354279  </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">        2</td><td>softmax            </td></tr>\n",
       "<tr><td>train_model_6ce31d26</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">       2.5</td><td style=\"text-align: right;\">0.0364661</td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>relu               </td><td style=\"text-align: right;\">         320</td><td style=\"text-align: right;\">    0.266372   </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">        4</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6ce57e4a</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">       2.5</td><td style=\"text-align: right;\">0.463574 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   10</td><td>elu                </td><td style=\"text-align: right;\">         900</td><td style=\"text-align: right;\">    0.0355628  </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">        3</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6ceb7598</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">       2.5</td><td style=\"text-align: right;\">0.0720379</td><td style=\"text-align: right;\">            0.0001</td><td style=\"text-align: right;\">                   20</td><td>tanh               </td><td style=\"text-align: right;\">         770</td><td style=\"text-align: right;\">    0.0121221  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">        2</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6ceded28</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">       0.5</td><td style=\"text-align: right;\">0.0859095</td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>selu               </td><td style=\"text-align: right;\">         360</td><td style=\"text-align: right;\">    0.00820041 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">        3</td><td>softmax            </td></tr>\n",
       "<tr><td>train_model_6cf07a16</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">       5  </td><td style=\"text-align: right;\">0.557945 </td><td style=\"text-align: right;\">            0.0001</td><td style=\"text-align: right;\">                   20</td><td>selu               </td><td style=\"text-align: right;\">         900</td><td style=\"text-align: right;\">    0.000641441</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">        3</td><td>softmax            </td></tr>\n",
       "<tr><td>train_model_6cf2e90e</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">       1  </td><td style=\"text-align: right;\">0.884504 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>relu               </td><td style=\"text-align: right;\">         430</td><td style=\"text-align: right;\">    0.539511   </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">        1</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6cf562c4</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">       2.5</td><td style=\"text-align: right;\">0.535158 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>relu               </td><td style=\"text-align: right;\">         670</td><td style=\"text-align: right;\">    0.00156185 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">        4</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6d08e268</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      10  </td><td style=\"text-align: right;\">0.555145 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>selu               </td><td style=\"text-align: right;\">         850</td><td style=\"text-align: right;\">    0.000279136</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">        1</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6d0b85e0</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">       2.5</td><td style=\"text-align: right;\">0.190273 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>tanh               </td><td style=\"text-align: right;\">         610</td><td style=\"text-align: right;\">    0.00872228 </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">        2</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6d0df8c0</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      10  </td><td style=\"text-align: right;\">0.434882 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   10</td><td>elu                </td><td style=\"text-align: right;\">         440</td><td style=\"text-align: right;\">    0.000329501</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">        3</td><td>softmax            </td></tr>\n",
       "<tr><td>train_model_6d17bb1c</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">       2.5</td><td style=\"text-align: right;\">0.307015 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>elu                </td><td style=\"text-align: right;\">         880</td><td style=\"text-align: right;\">    0.00910145 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">        4</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6d1a6498</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">       1  </td><td style=\"text-align: right;\">0.347464 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>tanh               </td><td style=\"text-align: right;\">         690</td><td style=\"text-align: right;\">    0.0463867  </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">        2</td><td>softmax            </td></tr>\n",
       "<tr><td>train_model_6d1c749a</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">      10  </td><td style=\"text-align: right;\">0.258334 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   10</td><td>elu                </td><td style=\"text-align: right;\">          80</td><td style=\"text-align: right;\">    0.000232179</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">        4</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6d26c4f4</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">       0.5</td><td style=\"text-align: right;\">0.443246 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>selu               </td><td style=\"text-align: right;\">         510</td><td style=\"text-align: right;\">    0.000277423</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">        2</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6d295a34</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">       1  </td><td style=\"text-align: right;\">0.294074 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   20</td><td>elu                </td><td style=\"text-align: right;\">         820</td><td style=\"text-align: right;\">    0.00171462 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">        1</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6d325cd8</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">       2.5</td><td style=\"text-align: right;\">0.679722 </td><td style=\"text-align: right;\">            0.0001</td><td style=\"text-align: right;\">                   20</td><td>elu                </td><td style=\"text-align: right;\">         490</td><td style=\"text-align: right;\">    0.000468305</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">        4</td><td>softmax            </td></tr>\n",
       "<tr><td>train_model_6d385c0a</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">       2.5</td><td style=\"text-align: right;\">0.723331 </td><td style=\"text-align: right;\">            0.0001</td><td style=\"text-align: right;\">                   10</td><td>tanh               </td><td style=\"text-align: right;\">         820</td><td style=\"text-align: right;\">    0.921041   </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">        1</td><td>sigmoid            </td></tr>\n",
       "<tr><td>train_model_6d3af3e8</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      10  </td><td style=\"text-align: right;\">0.665052 </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   10</td><td>selu               </td><td style=\"text-align: right;\">         750</td><td style=\"text-align: right;\">    0.00371045 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">        1</td><td>softmax            </td></tr>\n",
       "<tr><td>train_model_6cdad314</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">       5  </td><td style=\"text-align: right;\">0.2      </td><td style=\"text-align: right;\">            0.001 </td><td style=\"text-align: right;\">                   10</td><td>relu               </td><td style=\"text-align: right;\">        1000</td><td style=\"text-align: right;\">    0.0001     </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">        2</td><td>sigmoid            </td></tr>\n",
       "</tbody>\n",
       "</table><br>... 70 more trials not shown (70 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Model name nn_classifier.distilbert-base-multilingual-cased.all.30epochs.20-0.0010eStop.[100, 100]-relulayers-0.626338dropout.2-softmax.output.0.5.thresh.weighted.binary_crossentropyLoss.32batch.adam.0.0354lr.0.8696-0decay.5.00norm.ckpt\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Model name nn_classifier.distilbert-base-multilingual-cased.all.30epochs.10-0.0010eStop.[100, 100]-relulayers-0.200000dropout.2-sigmoid.output.0.5.thresh.weighted.binary_crossentropyLoss.64batch.adam.0.0001lr.0.8696-0decay.5.00norm.ckpt\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m 2020-05-29 18:57:57,083\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m 2020-05-29 18:57:57,083\tINFO trainable.py:217 -- Getting current IP.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2a1f5d061fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     ),\n\u001b[1;32m     47\u001b[0m     \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     verbose=1)\n\u001b[0m\u001b[1;32m     49\u001b[0m results.dataframe().to_csv(\n\u001b[1;32m     50\u001b[0m     '{0}/nn_results{1}layers.csv'.format(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         )\n\u001b[1;32m   1650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m (66338, 768) (66338,)\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m (4330, 768) (4330,)\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m (66338, 768) (66338,)\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m (4330, 768) (4330,)\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m 2020-05-29 18:57:59.230103: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m 2020-05-29 18:57:59.279858: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92bee5ca40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m 2020-05-29 18:57:59.279917: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m 2020-05-29 18:57:59.271177: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m 2020-05-29 18:57:59.309134: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92a71dc1b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m 2020-05-29 18:57:59.309193: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Model: \"sequential\"\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dense (Dense)                (None, 30)                23070     \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dropout (Dropout)            (None, 30)                0         \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dense_1 (Dense)              (None, 30)                930       \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dropout_1 (Dropout)          (None, 30)                0         \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dense_2 (Dense)              (None, 2)                 62        \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Total params: 24,062\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Trainable params: 24,062\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m None\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 1 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m   FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Class weights: {0: 0.6256602015001553, 1: 2.489492273730684}\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Model: \"sequential\"\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dense (Dense)                (None, 30)                23070     \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dropout (Dropout)            (None, 30)                0         \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dense_1 (Dense)              (None, 30)                930       \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dropout_1 (Dropout)          (None, 30)                0         \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m dense_2 (Dense)              (None, 2)                 62        \n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Total params: 24,062\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Trainable params: 24,062\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m None\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Train...\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Model: \"sequential\"\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dense (Dense)                (None, 1000)              769000    \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dropout (Dropout)            (None, 1000)              0         \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dense_1 (Dense)              (None, 1000)              1001000   \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dropout_1 (Dropout)          (None, 1000)              0         \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dense_2 (Dense)              (None, 2)                 2002      \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Total params: 1,772,002\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Trainable params: 1,772,002\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m None\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Class weights: {0: 0.6256602015001553, 1: 2.489492273730684}\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Model: \"sequential\"\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dense (Dense)                (None, 1000)              769000    \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dropout (Dropout)            (None, 1000)              0         \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dense_1 (Dense)              (None, 1000)              1001000   \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dropout_1 (Dropout)          (None, 1000)              0         \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m dense_2 (Dense)              (None, 2)                 2002      \n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Total params: 1,772,002\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Trainable params: 1,772,002\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m None\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Train...\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 1 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m   FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=33443)\u001b[0m Epoch 1/30\n",
      "\u001b[2m\u001b[36m(pid=33442)\u001b[0m Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# reporter = tune.CLIReporter()\n",
    "# reporter = tune.JupyterNotebookReporter(False)\n",
    "# reporter.add_metric_column('keras_info/label1_f1_score', 'f1-score')\n",
    "\n",
    "ray.shutdown()     # Restart Ray defensively in case the ray connection is lost.\n",
    "ray.init(num_cpus=2)\n",
    "results = tune.run(\n",
    "    train_model,\n",
    "    name=\"tune-nn-bert-classifier\",\n",
    "    config=_config,\n",
    "    stop={\n",
    "        \"keras_info/f1_score\": 0.99,\n",
    "        \"training_iteration\": 10**8\n",
    "    },\n",
    "    resources_per_trial={\n",
    "        \"cpu\": 1,\n",
    "        \"gpu\": 0\n",
    "    },\n",
    "    num_samples=_config[\"num_samples\"],\n",
    "    checkpoint_freq=0,\n",
    "    checkpoint_at_end=False,\n",
    "    scheduler=AsyncHyperBandScheduler(\n",
    "        time_attr='epoch',\n",
    "        metric='f1_score',\n",
    "        mode='max',\n",
    "        max_t=400,\n",
    "        grace_period=20),\n",
    "    search_alg=HyperOptSearch(\n",
    "        search_space,\n",
    "        metric=\"keras_info/f1_score\",\n",
    "        mode=\"max\",\n",
    "        random_state_seed=SEED,\n",
    "        points_to_evaluate=[{\n",
    "            \"dropout\": 0.2,\n",
    "            \"max_epochs\": 2,\n",
    "            \"early_stop_delta\": 0,\n",
    "            \"early_stop_patience\": 0,\n",
    "            \"hidden_activation\": 1,\n",
    "            \"output_activation\": 0,\n",
    "            \"clipnorm\": 3,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"batch_size\": 3,\n",
    "            \"nlayers\": 2,\n",
    "            \"layer_size\": 100            \n",
    "        }]\n",
    "    ),\n",
    "    progress_reporter=reporter,\n",
    "    verbose=1)\n",
    "results.dataframe().to_csv(\n",
    "    '{0}/nn_results{1}layers.csv'.format(\n",
    "        _config[\"train_dir\"], _config['layers']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_space = {\n",
    "    \"dropout\":\n",
    "        hp.uniform(\"dropout\", 0.0, 0.9),\n",
    "    \"max_epochs\":\n",
    "        hp.choice(\"max_epochs\", [10, 20, 30, 50]),\n",
    "    \"early_stop_delta\":\n",
    "        hp.choice(\"early_stop_delta\", [0.001, 0.0001]),\n",
    "    \"early_stop_patience\":\n",
    "        hp.choice(\"early_stop_patience\", [10, 20]),\n",
    "    \"hidden_activation\":\n",
    "        hp.choice(\"hidden_activation\", ['tanh', 'relu', 'elu', 'selu']),\n",
    "    \"output_activation\":\n",
    "        hp.choice(\"output_activation\", ['sigmoid', 'softmax']),\n",
    "    \"clipnorm\":\n",
    "        hp.choice(\"clipnorm\", [0.5, 1.0, 2.5, 5.0, 10.0]),\n",
    "    \"learning_rate\":\n",
    "        hp.loguniform(\"learning_rate\", np.log(1e-4), np.log(1e-0)),\n",
    "    \"batch_size\":\n",
    "        hp.choice(\"batch_size\", [20, 24, 32, 64, 128]),\n",
    "    \"nlayers\":\n",
    "        hp.randint('nlayers', 1, 5) * 1,\n",
    "    \"layer_size\":\n",
    "        hp.randint('layer_size', 1, 100) * 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 24,\n",
       " 'clipnorm': 1.0,\n",
       " 'dropout': 0.19698578209841475,\n",
       " 'early_stop_delta': 0.001,\n",
       " 'early_stop_patience': 10,\n",
       " 'hidden_activation': 'relu',\n",
       " 'layer_size': 70,\n",
       " 'learning_rate': 0.41547657526854137,\n",
       " 'max_epochs': 10,\n",
       " 'nlayers': 3,\n",
       " 'output_activation': 'softmax'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
