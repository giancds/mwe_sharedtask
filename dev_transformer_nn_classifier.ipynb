{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 57328,\n",
      "  \"iopub_port\": 57329,\n",
      "  \"stdin_port\": 57330,\n",
      "  \"control_port\": 57332,\n",
      "  \"hb_port\": 57331,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"78985efa-7fbd72bc5e451fce4ef811a7\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-5ab1cbd7-8ec4-4779-b8e4-4392728a67fd.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible models\n",
    "\n",
    "`bert-base-multilingual-cased`: (New, recommended) 12-layer, 768-hidden, 12-heads, 110M parameters. Trained on cased text in the top 104 languages with the largest Wikipedias\n",
    "\n",
    "`xlm-mlm-100-1280`: 16-layer, 1280-hidden, 16-heads XLM model trained with MLM (Masked Language Modeling) on 100 languages.\n",
    "\n",
    "`distilbert-base-multilingual-cased`: 6-layer, 768-hidden, 12-heads, 134M parameters The multilingual DistilBERT model distilled from the Multilingual BERT model bert-base-multilingual-cased checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = sys.argv[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from evaluation import  evaluate, MetricsReporterCallback\n",
    "from utils import build_model_name, convert_flags_to_dict, define_cnn_flags\n",
    "from preprocess import load_and_tokenize_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BASE_DIR = os.path.expanduser(\"~\")     # this will point to the user's home\n",
    "TRAIN_DIR = \"ray_results\"\n",
    "\n",
    "FLAGS = define_cnn_flags(tf.compat.v1.flags, BASE_DIR, TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'distilbert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "# transformer = TFAutoModel.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.conv_layers = [int(i) for i in FLAGS.conv_layers]\n",
    "FLAGS.dense_layers = [int(i) for i in FLAGS.dense_layers]\n",
    "\n",
    "_config = convert_flags_to_dict(FLAGS)\n",
    "_config[\"codes\"] = ([\"DE', 'GA', 'HI', 'PT', 'ZH\"]\n",
    "                    if FLAGS.language_code is 'all' else [FLAGS.language_code])\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "RESULTS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(config):\n",
    "\n",
    "    model_name = build_model_name(config)\n",
    "\n",
    "    with open('{}/data/{}.tokenized.pkl'.format(cwd, config[\"bert_type\"]),\n",
    "              'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    x_train, y_train, x_dev, y_dev = [], [], [], []\n",
    "    for code in config[\"codes\"]:\n",
    "        x_train += data[code][\"x_train\"]\n",
    "        y_train += data[code][\"y_train\"]\n",
    "\n",
    "        x_dev += data[code][\"x_dev\"]\n",
    "        y_dev += data[code][\"y_dev\"]\n",
    "\n",
    "    del data\n",
    "    \n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train)\n",
    "    max_len = x_train.shape[1]\n",
    "    y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train, maxlen=max_len)\n",
    "\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "                                                      y_train,\n",
    "                                                      test_size=0.15,\n",
    "                                                      random_state=SEED)\n",
    "\n",
    "    print(x_train.shape, x_train.shape, y_train.shape)\n",
    "    x_train = [x_train, (x_train > 0).astype(int)]\n",
    "    x_val = [x_val, (x_val > 0).astype(int)]\n",
    "\n",
    "    x_dev = tf.keras.preprocessing.sequence.pad_sequences(x_dev, maxlen=max_len)\n",
    "    x_dev = [x_dev, (x_dev > 0).astype(int)]\n",
    "\n",
    "    seq_lens = [len(seq) for seq in y_dev]\n",
    "    y_dev = tf.keras.preprocessing.sequence.pad_sequences(y_dev, maxlen=max_len)\n",
    "    print(x_dev[0].shape, x_dev[1].shape, y_dev.shape)\n",
    "\n",
    "   \n",
    "\n",
    "    conv_config = ([config[\"conv_size\"]] * config[\"nconv\"]\n",
    "                   if config[\"nconv\"] > 0 and config[\"conv_size\"] > 0\n",
    "                   else config[\"conv_layers\"])\n",
    "\n",
    "    dense_config = ([config[\"dense_size\"]] * config[\"ndense\"]\n",
    "                    if config[\"ndense\"] > 0 and config[\"dense_size\"] > 0\n",
    "                    else config[\"dense_layers\"])\n",
    "\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32)\n",
    "\n",
    "    # embedding\n",
    "    transformer = TFAutoModel.from_pretrained(config[\"bert_type\"])\n",
    "    out = transformer(\n",
    "        input_ids, attention_mask=attention_mask, training=False)[0]\n",
    "\n",
    "    for i, layer_size in enumerate(conv_config):\n",
    "        if i == 0:\n",
    "            out = tf.keras.layers.Conv1D(\n",
    "                layer_size,\n",
    "                config[\"strides\"],\n",
    "                padding='same',\n",
    "                activation=config[\"conv_activation\"],\n",
    "                strides=1,\n",
    "                input_shape=(None, x_train[0].shape[0], x_train[0].shape[1]))(out)\n",
    "        else:\n",
    "            out = tf.keras.layers.Conv1D(\n",
    "                layer_size,\n",
    "                config[\"strides\"],\n",
    "                padding='same',\n",
    "                activation=config[\"conv_activation\"],\n",
    "                strides=1)(out)\n",
    "        out = tf.keras.layers.Dropout(config[\"conv_dropout\"])(out)\n",
    "\n",
    "    # Dense layers\n",
    "    for i, layer_size in enumerate(dense_config):\n",
    "        out = tf.keras.layers.Dense(\n",
    "            layer_size, activation=config[\"dense_activation\"])(out)\n",
    "        out = tf.keras.layers.Dropout(config[\"dense_dropout\"])(out)\n",
    "\n",
    "    if config[\"output_size\"] == 1:\n",
    "        out = tf.keras.layers.Dense(1, activation='sigmoid')(out)\n",
    "    else:\n",
    "        out = tf.keras.layers.Dense(2, activation=config[\"output_activation\"])(out)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=out)\n",
    "\n",
    "    if config[\"optimizer\"] == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam\n",
    "    elif config[\"optimizer\"] == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD\n",
    "\n",
    "    # compiling model\n",
    "    model.compile(loss=config[\"loss_function\"],\n",
    "                  optimizer=optimizer(learning_rate=config[\"learning_rate\"],\n",
    "                                      clipnorm=config[\"clipnorm\"]),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "    # do this check again vecause we need y_train to be 1-D for class weights\n",
    "    if config[\"output_size\"] > 1:\n",
    "        y_train = tf.keras.utils.to_categorical(y_train)\n",
    "        y_val = tf.keras.utils.to_categorical(y_val)\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(config[\"train_dir\"] +\n",
    "                                                    model_name,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [checkpoint]\n",
    "\n",
    "    if config[\"tune\"]:\n",
    "        callbacks.append(\n",
    "            MetricsReporterCallback(custom_validation_data=(x_val, y_val)))\n",
    "\n",
    "    if config[\"early_stop_patience\"] > 0:\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            min_delta=config[\"early_stop_delta\"],\n",
    "            patience=config[\"early_stop_patience\"])\n",
    "        callbacks.append(early_stop)\n",
    "\n",
    "    if config[\"log_tensorboard\"]:\n",
    "        tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=config[\"train_dir\"] + '/logs')\n",
    "        callbacks.append(tensorboard)\n",
    "\n",
    "    def lr_scheduler(epoch, lr):     # pylint: disable=C0103\n",
    "        lr_decay = config[\"lr_decay\"]**max(epoch - config[\"start_decay\"], 0.0)\n",
    "        return lr * lr_decay\n",
    "\n",
    "    if config[\"start_decay\"] > 0:\n",
    "        lrate = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "        callbacks.append(lrate)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(x_train,\n",
    "              y_train,\n",
    "              batch_size=config[\"batch_size\"],\n",
    "              epochs=config[\"max_epochs\"],\n",
    "              callbacks=callbacks,\n",
    "              verbose=2,\n",
    "              validation_data=(x_val, y_val))\n",
    "\n",
    "    # #####\n",
    "    # Evaluation time\n",
    "    #\n",
    "    _results, y_pred = evaluate(\n",
    "        model,\n",
    "        test_data=(x_dev[0], y_dev),\n",
    "        perword=True,\n",
    "        seq_lens=seq_lens,\n",
    "        output_dict=True)\n",
    "\n",
    "\n",
    "    logs = {\n",
    "        \"dev_label0_support\" :_results[\"0\"][\"support\"],\n",
    "        \"dev_precision\" :_results[\"1\"][\"precision\"],\n",
    "        \"dev_recall\" :_results[\"1\"][\"recall\"],\n",
    "        \"dev_f1_score\" :_results[\"1\"][\"f1-score\"],\n",
    "        \"dev_label1_support\" :_results[\"1\"][\"support\"],\n",
    "        \"dev_macro_precision\" :_results[\"macro avg\"][\"precision\"],\n",
    "        \"dev_macro_recall\" :_results[\"macro avg\"][\"recall\"],\n",
    "        \"dev_macro_f1_score\" :_results[\"macro avg\"][\"f1-score\"],\n",
    "        \"dev_weighted_precision\" :_results[\"weighted avg\"][\"precision\"],\n",
    "        \"dev_weighted_recall\" :_results[\"weighted avg\"][\"recall\"],\n",
    "        \"dev_weighted_f1_score\" :_results[\"weighted avg\"][\"f1-score\"]}\n",
    "\n",
    "    trial_id = ray.tune.track.trial_id()\n",
    "\n",
    "    RESULTS[str(trial_id)] = logs\n",
    "\n",
    "    output_count = -1\n",
    "    y_pred = y_pred.reshape(-1,).tolist()\n",
    "    for code in config[\"codes\"]:\n",
    "        with open('{}/data/{}/dev.cupt'.format(cwd, code), 'r') as dev:\n",
    "            with open('{}/data/{}/dev.cupt'.format(cwd, code)) as test:\n",
    "                for line in dev:\n",
    "                    if not line.startswith('#') and line is not '\\n':\n",
    "                        test.write(line.replace('*', y_pred[output_count]))\n",
    "                        output_count += 1\n",
    "                    else:\n",
    "                        test.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_config['max_epochs'] = 1\n",
    "_config[\"codes\"] = ['GA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model name nn_classifier.distilbert-base-multilingual-cased.all.1epochs.10-0.0010eStop.2-100-sigmoidlayers1strides.-0.100dropout2-sigmoid.output.0.5.thresh.weighted.binary_crossentropyLoss.32batch.sgd.0.0001lr.0.8696-0decay.5.00norm.ckpt\n",
      "\n",
      "(218, 336) (218, 336) (218, 336)\n",
      "(322, 336) (322, 336) (322, 336)\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 336)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 336)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB ((None, 336, 768),)  134734080   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 336, 100)     76900       tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 336, 100)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 336, 100)     10100       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 336, 100)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 336, 100)     10100       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 336, 100)     0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 336, 100)     10100       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 336, 100)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 336, 2)       202         dropout_22[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 134,841,482\n",
      "Trainable params: 134,841,482\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 336)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 336)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB ((None, 336, 768),)  134734080   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 336, 100)     76900       tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 336, 100)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 336, 100)     10100       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 336, 100)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 336, 100)     10100       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 336, 100)     0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 336, 100)     10100       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 336, 100)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 336, 2)       202         dropout_22[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 134,841,482\n",
      "Trainable params: 134,841,482\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train...\n",
      "Train on 218 samples, validate on 39 samples\n"
     ]
    }
   ],
   "source": [
    "train_model(_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
