{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4EcbeP-7F94"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_DGhaUSB0mY"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = sys.argv[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEM3NMSb7gpZ"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import skorch\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import ProgressBar, EarlyStopping, Checkpoint\n",
    "from skorch.helper import predefined_split\n",
    "from torchtext.data import Dataset, Field, Example, BucketIterator\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# from evaluation import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7frPRyDGEbn"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Af-eSpyXFM45"
   },
   "outputs": [],
   "source": [
    "id_labels = {\n",
    "    0: 'none',\n",
    "    1: 'IAV',\n",
    "    2: 'IRV',\n",
    "    3: 'LVC.cause',\n",
    "    4: 'LVC.full',\n",
    "    5: 'MVC',\n",
    "    6: 'VID',\n",
    "    7: 'VPC.full',\n",
    "    8: 'VPC.semi',\n",
    "    9: '<unlabeled>'\n",
    "}\n",
    "\n",
    "\n",
    "def load_tokenized_data(datafile, language_codes, percent=0.15, seed=42):\n",
    "\n",
    "    with open(datafile, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    x_train, y_train = [], []\n",
    "    x_val, y_val = [], []\n",
    "    x_dev, y_dev = {}, {}\n",
    "    for code in language_codes:\n",
    "\n",
    "        true_x, true_y = [], []\n",
    "        false_x, false_y = [], []\n",
    "        for i, (xsample, ysample) in enumerate(zip(data[code]['x_train'], data[code]['y_train'])):\n",
    "            \n",
    "            if sum(ysample) > 0:\n",
    "                true_x.append(xsample)\n",
    "                true_y.append(ysample)\n",
    "\n",
    "        max_len = max([len(y) for y in true_y])\n",
    "        for xsample, ysample in zip(data[code]['x_train'], data[code]['y_train']):\n",
    "            if 1 not in ysample and len(ysample) < max_len:\n",
    "                false_x.append(xsample)\n",
    "                false_y.append(ysample)\n",
    "\n",
    "        false_x = np.array(false_x)\n",
    "        false_y = np.array(false_y)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        idx = np.random.randint(len(false_y), size=int(percent * len(true_y)))\n",
    "        false_x = false_x[idx].tolist()\n",
    "        false_y = false_y[idx].tolist()\n",
    "\n",
    "        x_train += true_x + false_x\n",
    "        y_train += true_y + false_y\n",
    "        x_val += data[code][\"x_dev\"]\n",
    "        y_val += data[code][\"y_dev\"]\n",
    "\n",
    "        x_dev[code] = data[code][\"x_dev\"]\n",
    "        y_dev[code] = data[code][\"y_dev\"]\n",
    "\n",
    "    del data\n",
    "\n",
    "    return (x_train, y_train),( x_val, y_val), (x_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecaCoKGYFsEe"
   },
   "outputs": [],
   "source": [
    "def build_model_name(args, model='rnn-cnn'):\n",
    "    name = ''\n",
    "    if model == 'rnn':\n",
    "        name = (\"{0}.{1}.{2}layers.{3}lstm.{4}dropout.{5}init.{6}activation\"\n",
    "                \"{7}clipnorm.{8}batch.{9}epochs\".format(\n",
    "                    args.bert_type, args.metric, args.nlayers, args.lstm_size,\n",
    "                    args.dropout, args.initrange, args.output_activation,\n",
    "                    args.clipnorm, args.batch_size, args.max_epochs\n",
    "                ))\n",
    "    elif model == 'cnn':\n",
    "        name = (\"{0}.{1}.{2}filters.{3}kernels.{4}poolstride.{5}dropout.\"\n",
    "                \"{6}activation.{7}batch.{8}epochs\".format(\n",
    "                    args.bert_type, args.metric, args.nfilters, args.kernels,\n",
    "                    args.pool_stride, args.dropout, args.output_activation,\n",
    "                    args.batch_size, args.max_epochs\n",
    "                ))\n",
    "    elif model == 'cnn-rnn':\n",
    "         name = (\"{0}.{1}.{2}filters.{3}kernels.{4}poolstride.{5}layers.\"\n",
    "                \"{6}lstm.{7}dropout.{8}init.{9}activation.{10}batch.\"\n",
    "                \"{11}epochs\".format(\n",
    "                    args.bert_type, args.metric, args.nfilters, args.kernels,\n",
    "                    args.pool_stride, args.nlayers, args.lstm_size, args.dropout,\n",
    "                    args.initrange, args.output_activation, args.batch_size,\n",
    "                    args.max_epochs\n",
    "                ))\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGpej-dKE5Nv"
   },
   "outputs": [],
   "source": [
    "class SkorchBucketIterator(BucketIterator):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch_size,\n",
    "                 sort_key=None,\n",
    "                 device=None,\n",
    "                 batch_size_fn=None,\n",
    "                 train=True,\n",
    "                 repeat=False,\n",
    "                 shuffle=None,\n",
    "                 sort=None,\n",
    "                 sort_within_batch=None,\n",
    "                 one_hot=True,\n",
    "                 num_classes=2):\n",
    "        self.one_hot = one_hot\n",
    "        self.num_classes = num_classes\n",
    "        super(SkorchBucketIterator,\n",
    "              self).__init__(dataset, batch_size, sort_key, device,\n",
    "                             batch_size_fn, train, repeat, shuffle, sort,\n",
    "                             sort_within_batch)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in super().__iter__():\n",
    "            # We make a small modification: Instead of just returning batch\n",
    "            # we return batch.text and batch.label, corresponding to X and y\n",
    "            # if self.train:\n",
    "            if self.one_hot:\n",
    "                y = batch.labels.to('cpu')\n",
    "                y = to_categorical(y, num_classes=self.num_classes)\n",
    "                y = torch.tensor(y).to(self.device)\n",
    "                batch.labels = y\n",
    "            else:\n",
    "                batch.labels = batch.labels.float()\n",
    "            yield batch.sentence, batch.labels\n",
    "\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, min_len=5, **kwargs):\n",
    "        self.min_len = min_len\n",
    "        text_field = Field(use_vocab=False, pad_token=0, batch_first=True)\n",
    "        label_field = Field(use_vocab=False, pad_token=-1, batch_first=True)\n",
    "        fields = [(\"sentence\", text_field), (\"labels\", label_field)]\n",
    "        examples = []\n",
    "        for (x, y) in zip(data[0], data[1]):\n",
    "            if len(x) < self.min_len:     # pad all sequences shorter than this\n",
    "                x += [0] * (5 - len(x))\n",
    "                y += [-1] * (5 - len(y))\n",
    "            examples.append(Example.fromlist([x, y], fields))\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "\n",
    "class IdiomClassifier(skorch.NeuralNetClassifier):\n",
    "\n",
    "    def __init__(self, print_report=True, class_weights=None, score_average='binary', *args, **kwargs):\n",
    "        self.print_report = print_report\n",
    "        self.class_weights = class_weights\n",
    "        self.score_average = score_average\n",
    "        if class_weights is None:\n",
    "            self.class_weights = [1.0, 1.0]\n",
    "        super(IdiomClassifier, self).__init__(*args, **kwargs)\n",
    "        self.set_params(callbacks__valid_acc=None)\n",
    "        self.set_params(criterion__reduction='none')\n",
    "\n",
    "    def get_loss(self, y_pred, y_true, X, *args, **kwargs):\n",
    "        if isinstance(self.criterion_, torch.nn.NLLLoss):\n",
    "            loss = super().get_loss(y_pred.view(-1, 10), y_true.long().view(-1), X, *args, **kwargs)\n",
    "        else:\n",
    "            loss = super().get_loss(y_pred.view(-1), y_true.view(-1), X, *args,\n",
    "                                        **kwargs)\n",
    "        weights = torch.ones_like(y_true) * y_true\n",
    "        for w, weight in enumerate(self.class_weights):\n",
    "            weights = torch.where(\n",
    "                y_true == w,\n",
    "                torch.tensor(weight).float().to(self.device),\n",
    "                weights)\n",
    "        loss = (loss * weights.view(-1))\n",
    "        mask = (y_true >= 0).int()\n",
    "        loss = (loss * mask.view(-1)).mean()\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.module.eval()\n",
    "        y_pred = self.module(X)\n",
    "        if len(y_pred.shape) > 2:\n",
    "            y_pred = torch.argmax(y_pred, dim=2)\n",
    "        else:\n",
    "            y_pred = (y_pred > 0.5).int()\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        self.module.eval()\n",
    "        ds = self.get_dataset(X)\n",
    "        target_iterator = self.get_iterator(ds, training=False)\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for x, y in target_iterator:\n",
    "            preds = self.predict(x)\n",
    "            y_pred.append(preds.view(-1))\n",
    "            if len(y.shape) > 2:\n",
    "                y = torch.argmax(y, dim=2)\n",
    "            y_true.append(y.view(-1))\n",
    "        y_true = torch.cat(y_true).cpu().view(-1).detach().numpy().tolist()\n",
    "        y_pred = torch.cat(y_pred).cpu().view(-1).detach().numpy().tolist()\n",
    "\n",
    "        tt, tp = [], []\n",
    "        for t, p in zip(y_true, y_pred):\n",
    "            if t >= 0:\n",
    "                tt.append(t)\n",
    "                tp.append(p)\n",
    "\n",
    "        y_true = tt\n",
    "        y_pred = tp\n",
    "\n",
    "        if self.print_report:\n",
    "            print('Confusion matrix')\n",
    "            print(confusion_matrix(y_true, y_pred))\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        return f1_score(y_true, y_pred, average=self.score_average)\n",
    "\n",
    "\n",
    "class CustomScorer(skorch.callbacks.EpochScoring):\n",
    "\n",
    "    def on_epoch_end(self, net, dataset_train, dataset_valid, **kwargs):\n",
    "        current_score = net.score(dataset_valid)\n",
    "        self._record_score(net.history, current_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvcm3d6JFdp6"
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, config, transformer, transformer_device):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "\n",
    "        self.transformer_device = transformer_device\n",
    "        self.model_device = transformer_device\n",
    "        self.transformer = transformer\n",
    "        self.convolutions = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=transformer.embeddings.word_embeddings.embedding_dim,\n",
    "                out_channels=config.nfilters,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1) for kernel_size in config.kernels])\n",
    "\n",
    "        self.pool_stride = config.pool_stride\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        ninputs = (config.nfilters // config.pool_stride) * len(config.kernels)\n",
    "        noutputs = 1\n",
    "\n",
    "        if config.labels == 'multilabel':\n",
    "            noutputs = 10\n",
    "        else:\n",
    "            if config.output_activation == 'softmax':\n",
    "                noutputs = 2\n",
    "\n",
    "        self.fully_connected = nn.Linear(ninputs, noutputs)\n",
    "\n",
    "        self.output_activation = (torch.sigmoid  # pylint: disable=no-member\n",
    "                                  if noutputs == 1\n",
    "                                  else F.softmax)\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        self = super().to(*args, **kwargs)\n",
    "        self.transformer = self.transformer.to(\n",
    "            torch.device(self.transformer_device))\n",
    "        self.model_device = next(self.fully_connected.parameters()).device.type\n",
    "        return self\n",
    "\n",
    "    def freeze_transformer(self):\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_transformer(self):\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.transformer_device)\n",
    "        m = (x > 0).int()\n",
    "        x = self.transformer(x, attention_mask=m)[0].transpose(1, 2)\n",
    "        #\n",
    "        seq_len = x.shape[-1]\n",
    "        #\n",
    "        if self.transformer_device != self.model_device:\n",
    "            x = x.to(self.model_device)\n",
    "        #\n",
    "        x = [F.relu(conv(x)).transpose(1, 2) for conv in self.convolutions]\n",
    "        x = [nn.functional.pad(i, (0, 0, 0, seq_len - i.shape[1])) for i in x]\n",
    "        x = [F.max_pool1d(c, self.pool_stride) for c in x]\n",
    "        x = torch.cat(x, dim=2)  # pylint: disable=no-member\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.output_activation(x, dim=2)\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, config, transformer, transformer_device):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "\n",
    "        self.transformer_device = transformer_device\n",
    "        self.model_device = transformer_device\n",
    "        self.transformer = transformer\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=transformer.embeddings.word_embeddings.embedding_dim,\n",
    "            hidden_size=config.lstm_size,\n",
    "            num_layers=config.nlayers,\n",
    "            batch_first=True,\n",
    "            dropout=config.dropout)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        noutputs = (1 if config.output_activation == 'sigmoid' else 2)\n",
    "\n",
    "        self.fully_connected = nn.Linear(config.lstm_size, noutputs)\n",
    "\n",
    "        self.output_activation = (torch.sigmoid  # pylint: disable=no-member\n",
    "                                  if noutputs == 1\n",
    "                                  else F.softmax)\n",
    "        self.init_weights(config.initrange)\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        self = super().to(*args, **kwargs)\n",
    "        self.transformer = self.transformer.to(\n",
    "            torch.device(self.transformer_device))\n",
    "        self.model_device = next(self.fully_connected.parameters()).device.type\n",
    "        return self\n",
    "\n",
    "    def freeze_transformer(self):\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_transformer(self):\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.transformer_device)\n",
    "        m = (x > 0).int()\n",
    "        x = self.transformer(x, attention_mask=m)[0]\n",
    "        #\n",
    "        seq_len = x.shape[-1]\n",
    "        #\n",
    "        if self.transformer_device != self.model_device:\n",
    "            x = x.to(self.model_device)\n",
    "        #\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fully_connected(x)\n",
    "\n",
    "        return self.output_activation(x)\n",
    "\n",
    "    def init_weights(self, initrange):\n",
    "        for names in self.lstm._all_weights:\n",
    "            for name in filter(lambda n: \"bias\" in n, names):\n",
    "                bias = getattr(self.lstm, name)\n",
    "                n = bias.size(0)\n",
    "                start, end = n//4, n//2\n",
    "                bias.data[start:end].fill_(1.)\n",
    "            for name in filter(lambda n: \"weight\" in n,  names):\n",
    "                weight = getattr(self.lstm, name)\n",
    "                weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        self.fully_connected.bias.data.fill_(0)\n",
    "        self.fully_connected.weight.data.uniform_(-initrange, initrange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NIPFLxs7grp"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')     # pylint: disable=no-member\n",
    "LANGUAGE_CODES = ['DE', 'GA', 'HI', 'PT', 'ZH']\n",
    "CWD = os.getcwd()\n",
    "BASE_DIR = ''     # this will point to the user's home\n",
    "TRAIN_DIR = \"transformer/cnn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9KMyS3WM7g5V",
    "outputId": "1eeba5e2-7ff0-46ee-da2b-771f3f97d211"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Classifier using CNNs')\n",
    "parser.add_argument(\n",
    "    '--bert_type',\n",
    "    type=str,\n",
    "    default='distilbert-base-multilingual-cased',\n",
    "    help='transormer model [should be a miltilingual model]')\n",
    "parser.add_argument(\n",
    "    '--bert_device',\n",
    "    type=str,\n",
    "    default='gpu',\n",
    "    help='device to run the transformer model')\n",
    "parser.add_argument(\n",
    "    '--labels',\n",
    "    type=str,\n",
    "    default='multilabel',\n",
    "    help='multilabel or binary classification')\n",
    "parser.add_argument(\n",
    "    '--metric',\n",
    "    type=str,\n",
    "    default='f1',\n",
    "    help='sklearn metric to evaluate the model while training')\n",
    "parser.add_argument(\n",
    "    '--nfilters',\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help='number of convolution filters')\n",
    "parser.add_argument(\n",
    "    '--kernels',\n",
    "    type=list,\n",
    "    default=[1, 3, 5],\n",
    "    help='number of convolution filters')\n",
    "parser.add_argument(\n",
    "    '--pool_stride',\n",
    "    type=int,\n",
    "    default=2,\n",
    "    help='size of the stride for the pooling operation')\n",
    "parser.add_argument(\n",
    "    '--nlayers',\n",
    "    type=int,\n",
    "    default=2,\n",
    "    help='number of convolution filters')\n",
    "parser.add_argument(\n",
    "    '--lstm_size',\n",
    "    type=int,\n",
    "    default=50,\n",
    "    help='number of convolution filters')\n",
    "parser.add_argument(\n",
    "    '--dropout',\n",
    "    type=float,\n",
    "    default=0.2,\n",
    "    help='dropout probability for the dense layer')\n",
    "parser.add_argument(\n",
    "    '--initrange',\n",
    "    type=float,\n",
    "    default=0.1,\n",
    "    help='range to initialize the lstm layers')\n",
    "parser.add_argument(\n",
    "    '--clipnorm',\n",
    "    type=float,\n",
    "    default=5.0,\n",
    "    help='limit to clip the l2 norm of gradients')\n",
    "parser.add_argument(\n",
    "    '--output_activation',\n",
    "    type=str,\n",
    "    default='sigmoid',\n",
    "    help='output activation')\n",
    "parser.add_argument(\n",
    "    '--batch_size',\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help='training batch size')\n",
    "parser.add_argument(\n",
    "    '--eval_batch_size',\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help='validation/evaluation batch size')\n",
    "parser.add_argument(\n",
    "    '--max_epochs',\n",
    "    type=int,\n",
    "    default=100,\n",
    "    help='max number of epochs to train the model')\n",
    "parser.add_argument(\n",
    "    \"--train_dir\",\n",
    "    type=str,\n",
    "    default=os.path.join(BASE_DIR, TRAIN_DIR) + \"/\",\n",
    "    help=\"Train dir\")\n",
    "parser.add_argument(\n",
    "    \"--eval\",\n",
    "    action=\"store_true\",\n",
    "    help=\"eval at the end of the training process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5iVJ5HpK7hC7",
    "outputId": "633ee806-7640-4597-8e0d-f3b5405ac3fa"
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args()\n",
    "args.kernels = [int(i) for i in args.kernels if ',' not in str(i)]\n",
    "transformer_device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() and args.bert_device == 'gpu'\n",
    "    else 'cpu')\n",
    "\n",
    "ONE_HOT_OUTPUT = args.output_activation == 'softmax' or args.labels == 'binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtYM8yfG7g25"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_dev, y_dev) = load_tokenized_data(\n",
    "    datafile='data/{}{}.tokenized.pkl'.format(args.bert_type, '' if args.labels == 'binary' else '.multilabel'),\n",
    "    language_codes=LANGUAGE_CODES,\n",
    "    seed=SEED)\n",
    "\n",
    "targets = np.concatenate(y_train).reshape(-1)\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(targets),\n",
    "                                     y=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o1zspe5Z7g15"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.bert_type)\n",
    "transformer = AutoModel.from_pretrained(args.bert_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RB79j7xQ7g01"
   },
   "outputs": [],
   "source": [
    "model = CNNClassifier(args, transformer, transformer_device)\n",
    "model_name = build_model_name(args, model='cnn')\n",
    "\n",
    "model.to(DEVICE)     # pylint: disable=no-member\n",
    "model.freeze_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OgdFwcZLdcW"
   },
   "outputs": [],
   "source": [
    "progress_bar = ProgressBar(batches_per_epoch=len(x_train) // args.batch_size + 1)\n",
    "scorer = CustomScorer(scoring=None, name=\"F1\", lower_is_better=False, use_caching=False)\n",
    "early_stopping =  EarlyStopping(monitor='F1', patience=20, lower_is_better=False)\n",
    "checkpoint = Checkpoint(\n",
    "    monitor='F1_best',\n",
    "    dirname=args.train_dir,\n",
    "    f_params='{}.params.pt'.format(model_name),\n",
    "    f_optimizer='{}.optimizer.pt'.format(model_name),\n",
    "    f_history='{}.history.json'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsGdaUd-7gzf"
   },
   "outputs": [],
   "source": [
    "net = IdiomClassifier(\n",
    "    module=model,\n",
    "    class_weights=class_weights,\n",
    "    print_report=False,\n",
    "    score_average='micro',\n",
    "     #\n",
    "    iterator_train=SkorchBucketIterator,\n",
    "    iterator_train__batch_size=args.batch_size,\n",
    "    iterator_train__sort_key=lambda x: len(x.sentence),\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__device=DEVICE,\n",
    "    iterator_train__one_hot=ONE_HOT_OUTPUT,\n",
    "     #\n",
    "    iterator_valid=SkorchBucketIterator,\n",
    "    iterator_valid__batch_size=32,\n",
    "    iterator_valid__sort_key=lambda x: len(x.sentence),\n",
    "    iterator_valid__shuffle=True,\n",
    "    iterator_valid__device=DEVICE,\n",
    "    iterator_valid__one_hot=ONE_HOT_OUTPUT,\n",
    "\n",
    "    train_split=predefined_split(SentenceDataset(data=(x_val[0:5], y_val[0:5]))),\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=nn.BCELoss if args.labels == 'binary' else nn.NLLLoss,\n",
    "    criterion__ignore_index=-1,\n",
    "    callbacks=[progress_bar, scorer, early_stopping, checkpoint],\n",
    "    device=DEVICE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "IgUU4f0V7gwd",
    "outputId": "5392f2c7-5ee0-4496-fe08-4c11f77d4d6f"
   },
   "outputs": [],
   "source": [
    "net.fit(SentenceDataset(data=(x_train[0:32], y_train[0:32])), y=None, epochs=1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrthjRiPLUL7"
   },
   "outputs": [],
   "source": [
    "# net.initialize()\n",
    "# net.load_params(checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxkiOcTagyDW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-base-multilingual-cased.f1.32filters.[1, 3, 5]kernels.2poolstride.0.2dropout.sigmoidactivation.32batch.100epochs\n",
      "####################\n",
      "# Evaluating Language: GA\n",
      "####################\n",
      "0\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Line has 162 columns, but header specifies 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ad92490ec953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             device=DEVICE)\n\u001b[1;32m     18\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/{}/dev.cupt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-8c9ad817eb5c>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(net, test_iterator, tokenizer, args)\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0m_run_sript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-8c9ad817eb5c>\u001b[0m in \u001b[0;36m_run_sript\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev.cupt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train.cupt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mMain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/research/mwe_sharedtask/eval_scripts/evaluate.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mmc_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtractable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinatorial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsvlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_tsv_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsvlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_tsv_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeenInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/research/mwe_sharedtask/eval_scripts/tsvlib.py\u001b[0m in \u001b[0;36miter_tsv_sentences\u001b[0;34m(fileobj)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 raise Exception('Line has {} columns, but header specifies {}' \\\n\u001b[0m\u001b[1;32m    253\u001b[0m                                 .format(len(fields), len(colnames)))\n\u001b[1;32m    254\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mUNDERSP\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Line has 162 columns, but header specifies 11"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "args.eval = True\n",
    "LANGUAGE_CODES = ['GA']\n",
    "if args.eval:\n",
    "    for code in LANGUAGE_CODES:\n",
    "        print('#' * 20)\n",
    "        print('# Evaluating Language: {}'.format(code))\n",
    "        print('#' * 20)\n",
    "        test_iterator = SkorchBucketIterator(\n",
    "            dataset=SentenceDataset(data=(x_dev[code], y_dev[code])),\n",
    "            batch_size=args.eval_batch_size,\n",
    "            sort=False,\n",
    "            sort_key=lambda x: len(x.sentence),\n",
    "            shuffle=False,\n",
    "            train=False,\n",
    "            one_hot=ONE_HOT_OUTPUT,\n",
    "            device=DEVICE)\n",
    "        args.dev_file = 'data/{}/dev.cupt'.format(code)\n",
    "        evaluate_model(net, test_iterator, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_scripts.evaluate import Main\n",
    "\n",
    "\n",
    "ID_LABELS = {\n",
    "    0: 'none',\n",
    "    1: 'IAV',\n",
    "    2: 'IRV',\n",
    "    3: 'LVC.cause',\n",
    "    4: 'LVC.full',\n",
    "    5: 'MVC',\n",
    "    6: 'VID',\n",
    "    7: 'VPC.full',\n",
    "    8: 'VPC.semi',\n",
    "    9: '<unlabeled>'\n",
    "}\n",
    "\n",
    "def evaluate_model(net, test_iterator, tokenizer, args):\n",
    "    preds = []\n",
    "    sents = []\n",
    "    i = 0\n",
    "    for x, y in test_iterator:\n",
    "        y_pred = net.predict(x)\n",
    "    #     i += 1\n",
    "        if i % 40 == 0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "        sub_tokens = []\n",
    "        sub_preds = []\n",
    "        text = []\n",
    "        predictions = []\n",
    "        tokens = tokenizer.convert_ids_to_tokens(x.detach().cpu().numpy().reshape(-1))\n",
    "        # tokens = tokens\n",
    "        y_pred = y_pred.cpu().detach().reshape(-1).tolist()\n",
    "        for t, p in zip(tokens, y_pred):\n",
    "            if '#' in t:\n",
    "                sub_tokens.append(t.replace('#', ''))\n",
    "                sub_preds.append(p)\n",
    "            else:\n",
    "                if sub_tokens:\n",
    "                    old_token = ''.join([text[-1]] + sub_tokens)\n",
    "                    old_pred = sum(sub_preds)\n",
    "                    text = text[0:-1]\n",
    "                    text.append(old_token)\n",
    "                    predictions = predictions[0:-1]\n",
    "                    predictions.append(old_pred if old_pred == 0 else 1)\n",
    "                    old_token = t\n",
    "                    old_pred = p\n",
    "                    sub_tokens = []\n",
    "                    sub_preds = []\n",
    "                else:\n",
    "                    old_token = t\n",
    "                    old_pred = p\n",
    "                text.append(old_token)\n",
    "                predictions.append(old_pred)\n",
    "                assert len(text[1:-1]) == len(predictions[1:-1])\n",
    "        sents.append(text[1:-1])\n",
    "        preds += predictions[1:-1]\n",
    "\n",
    "    output_count = 0\n",
    "    with open(args.dev_file, 'r') as dev:\n",
    "        with open(args.dev_file.replace('dev.cupt', 'temp.cupt'), 'w') as test:\n",
    "            for line in dev:\n",
    "                feats = line.split()\n",
    "                if not line.startswith('#') and line != '\\n' and '-' not in feats[0]:\n",
    "                    prediction = preds[output_count]\n",
    "                    if prediction == 0:\n",
    "                        label = '*'\n",
    "                    else:\n",
    "                        label = ID_LABELS.get(prediction, '*')\n",
    "                    new_line = '\\t'.join(\n",
    "                        [str(f) for f in feats[0:-1]] + [str(label)] + ['\\n'])\n",
    "                    test.write(new_line)\n",
    "                    output_count += 1\n",
    "                else:\n",
    "                    test.write(line)\n",
    "\n",
    "    # post-process the file to get the predictions into cupt format\n",
    "    with open(args.dev_file.replace('dev.cupt', 'temp.cupt'), 'r') as temp:\n",
    "        with open(args.dev_file.replace('dev.cupt', 'system.cupt'), 'w') as test:\n",
    "            current_prediction = [1, None]\n",
    "            verb_found = False\n",
    "            for line in temp:\n",
    "                feats = line.split('\\t')\n",
    "                if not line.startswith('#') and line != '\\n' and '-' not in feats[0]:\n",
    "\n",
    "                    if feats[10] == '*':\n",
    "                        test.write(line)\n",
    "                    else:\n",
    "\n",
    "                        if current_prediction[1] is None:\n",
    "\n",
    "                            label = '{}:{}'.format(current_prediction[0], feats[10])\n",
    "                            verb_found = True if feats[3] == 'VERB' else False\n",
    "                            current_prediction[1] = feats[10]\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            if feats[10] == current_prediction[1]:\n",
    "\n",
    "                                if verb_found and feats[3] != 'VERB':\n",
    "                                    label = current_prediction[0]\n",
    "\n",
    "                                elif verb_found and feats[3] == 'VERB':\n",
    "                                    current_prediction[0] = current_prediction[0] + 1\n",
    "                                    current_prediction[1] = feats[10]\n",
    "                                    label = '{}:{}'.format(current_prediction[0], feats[10])\n",
    "\n",
    "                                elif not verb_found:\n",
    "                                    label = current_prediction[0]\n",
    "                                    verb_found = True if feats[3] == 'VERB' else False\n",
    "\n",
    "                            else:\n",
    "                                current_prediction[0] = current_prediction[0] + 1\n",
    "                                current_prediction[1] = feats[10]\n",
    "                                label = '{}:{}'.format(current_prediction[0], feats[10])\n",
    "                                verb_found = True if feats[3] == 'VERB' else False\n",
    "                        test.write('\\t'.join(feats[0:-2] + [str(label)]))\n",
    "                else:\n",
    "                    if line == '\\n':\n",
    "                        current_prediction = [1, None]\n",
    "                        verb_found = False\n",
    "                    test.write(line)\n",
    "    if args.eval:\n",
    "        _run_sript(args)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _run_sript(args):\n",
    "\n",
    "    args.debug = False\n",
    "    args.combinatorial = True\n",
    "    args.gold_file = open(args.dev_file, 'r')\n",
    "    args.prediction_file = open(args.dev_file.replace('dev.cupt', 'system.cupt'), 'r')\n",
    "    args.train_file = open(args.dev_file.replace('dev.cupt', 'train.cupt'), 'r')\n",
    "\n",
    "    Main(args).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jX5Yc2I9rhj"
   },
   "outputs": [],
   "source": [
    "print(\"#\" * 20)\n",
    "print(\"\\nTraining finished!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPnUSkWIKT_j"
   },
   "outputs": [],
   "source": [
    "net.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'GA'\n",
    "test_iterator = SkorchBucketIterator(\n",
    "            dataset=SentenceDataset(data=(x_dev[code], y_dev[code])),\n",
    "            batch_size=args.eval_batch_size,\n",
    "            sort=False,\n",
    "            sort_key=lambda x: len(x.sentence),\n",
    "            shuffle=False,\n",
    "            train=False,\n",
    "            one_hot=ONE_HOT_OUTPUT,\n",
    "            device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args.dev_file = 'data/{}/dev.cupt'.format(code)\n",
    "evaluate_model(net, test_iterator, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(torch.tensor([[0.25, 0.75], [0.5, 0.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(test_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.to(self.transformer_device)\n",
    "m = (x > 0).int()\n",
    "x = transformer(x, attention_mask=m)[0].transpose(1, 2)\n",
    "#\n",
    "seq_len = x.shape[-1]\n",
    "#\n",
    "# if self.transformer_device != self.model_device:\n",
    "#     x = x.to(self.model_device)\n",
    "#\n",
    "x = [F.relu(conv(x)).transpose(1, 2) for conv in net.module.convolutions]\n",
    "x = [nn.functional.pad(i, (0, 0, 0, seq_len - i.shape[1])) for i in x]\n",
    "x = [F.max_pool1d(c, net.module.pool_stride) for c in x]\n",
    "x = torch.cat(x, dim=2)  # pylint: disable=no-member\n",
    "x = net.module.fully_connected(x)\n",
    "x = net.module.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.softmax(x, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0, 0, :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t'.join(['1', '2', '3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {1: 'one', 2: 'two'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'one' in d.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([k for k in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([k for k in d.keys()])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(11)][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"# source_sent_id = http://hdl.handle.net/11234/1-3105 UD_Irish-IDT/ga_idt-ud-dev 547\n",
    "# text = Nuair a chuaigh Éamonn i mbun oibre bhí sé i gceist aige an oifig a riar go héifeachtach ach chuir na riaráistí oibre alltacht air.\n",
    "1\tNuair\tnuair\tSCONJ\tSubord\t_\t3\tmark\t_\t_\t*\n",
    "2\ta\ta\tPART\tVb\tPartType=Vb|PronType=Rel\t3\tmark:prt\t_\t_\t*\n",
    "3\tchuaigh\ttéigh\tVERB\tVTI\tForm=Len|Mood=Ind|Tense=Past\t8\tadvcl\t_\t_\t1:VID\n",
    "4\tÉamonn\tÉamonn\tNOUN\tNoun\tGender=Masc|Number=Sing\t3\tnsubj\t_\t_\t*\n",
    "5\ti\ti\tADP\tCmpd\tPrepForm=Cmpd\t7\tcase\t_\t_\t1\n",
    "6\tmbun\tmbun\tADP\tCmpd\tPrepForm=Cmpd\t5\tfixed\t_\t_\t1\n",
    "7\toibre\tobair\tNOUN\tNoun\tCase=Gen|Gender=Fem|Number=Sing\t3\tobl\t_\t_\t*\n",
    "8\tbhí\tbí\tVERB\tPastInd\tForm=Len|Mood=Ind|Tense=Past\t0\troot\t_\t_\t*\n",
    "9\tsé\tsé\tPRON\tPers\tGender=Masc|Number=Sing|Person=3\t8\tnsubj\t_\t_\t*\n",
    "10\ti\ti\tADP\tSimp\t_\t11\tcase\t_\t_\t*\n",
    "11\tgceist\tceist\tNOUN\tNoun\tForm=Ecl|Gender=Fem|Number=Sing\t8\txcomp:pred\t_\t_\t*\n",
    "12\taige\tag\tADP\tPrep\tGender=Masc|Number=Sing|Person=3\t8\tobl:prep\t_\t_\t*\n",
    "13\tan\tan\tDET\tArt\tDefinite=Def|Number=Sing|PronType=Art\t14\tdet\t_\t_\t*\n",
    "14\toifig\toifig\tNOUN\tNoun\tDefinite=Def|Gender=Fem|Number=Sing\t16\tobj\t_\t_\t*\n",
    "15\ta\ta\tPART\tInf\tPartType=Inf\t16\tmark\t_\t_\t*\n",
    "16\triar\triar\tNOUN\tNoun\tVerbForm=Inf\t8\txcomp\t_\t_\t*\n",
    "17\tgo\tgo\tPART\tAd\tPartType=Ad\t18\tmark:prt\t_\t_\t*\n",
    "18\théifeachtach\téifeachtach\tADJ\tAdj\tDegree=Pos|Form=HPref\t16\tadvmod\t_\t_\t*\n",
    "19\tach\tach\tSCONJ\tSubord\t_\t20\tmark\t_\t_\t*\n",
    "20\tchuir\tcuir\tVERB\tVTI\tForm=Len|Mood=Ind|Tense=Past\t8\tadvcl\t_\t_\t2:LVC.cause\n",
    "21\tna\tna\tDET\tArt\tDefinite=Def|Number=Plur|PronType=Art\t22\tdet\t_\t_\t*\n",
    "22\triaráistí\triaráiste\tNOUN\tNoun\tDefinite=Def|Gender=Masc|Number=Plur\t20\tnsubj\t_\t_\t*\n",
    "23\toibre\tobair\tNOUN\tNoun\tCase=Gen|Gender=Fem|Number=Sing\t22\tnmod\t_\t_\t*\n",
    "24\talltacht\talltacht\tNOUN\tNoun\tGender=Fem|Number=Sing\t20\tobj\t_\t_\t2\n",
    "25\tair\tar\tADP\tPrep\tGender=Masc|Number=Sing|Person=3\t20\tobl:prep\t_\tSpaceAfter=No\t*\n",
    "26\t.\t.\tPUNCT\t.\t_\t8\tpunct\t_\t_\t*\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prediction = [1, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prediction[1] = 'VERB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev =  \"\"\"# source_sent_id = http://hdl.handle.net/11234/1-3105 UD_Irish-IDT/ga_idt-ud-dev 547\\n\n",
    "# text = Nuair a chuaigh Éamonn i mbun oibre bhí sé i gceist aige an oifig a riar go héifeachtach ach chuir na riaráistí oibre alltacht air.\\n\n",
    "1\tNuair\tnuair\tSCONJ\tSubord\t_\t3\tmark\t_\t_\t*\\n\n",
    "2\ta\ta\tPART\tVb\tPartType=Vb|PronType=Rel\t3\tmark:prt\t_\t_\t*\\n\n",
    "3\tchuaigh\ttéigh\tVERB\tVTI\tForm=Len|Mood=Ind|Tense=Past\t8\tadvcl\t_\t_\tVID\\n\n",
    "4\tÉamonn\tÉamonn\tNOUN\tNoun\tGender=Masc|Number=Sing\t3\tnsubj\t_\t_\t*\\n\n",
    "5\ti\ti\tADP\tCmpd\tPrepForm=Cmpd\t7\tcase\t_\t_\tVID\\n\n",
    "6\tmbun\tmbun\tADP\tCmpd\tPrepForm=Cmpd\t5\tfixed\t_\t_\tVID\\n\n",
    "7\toibre\tobair\tNOUN\tNoun\tCase=Gen|Gender=Fem|Number=Sing\t3\tobl\t_\t_\t*\\n\n",
    "8\tbhí\tbí\tVERB\tPastInd\tForm=Len|Mood=Ind|Tense=Past\t0\troot\t_\t_\t*\\n\n",
    "9\tsé\tsé\tPRON\tPers\tGender=Masc|Number=Sing|Person=3\t8\tnsubj\t_\t_\t*\\n\n",
    "10\ti\ti\tADP\tSimp\t_\t11\tcase\t_\t_\t*\\n\n",
    "11\tgceist\tceist\tNOUN\tNoun\tForm=Ecl|Gender=Fem|Number=Sing\t8\txcomp:pred\t_\t_\t*\\n\n",
    "12\taige\tag\tADP\tPrep\tGender=Masc|Number=Sing|Person=3\t8\tobl:prep\t_\t_\t*\\n\n",
    "13\tan\tan\tDET\tArt\tDefinite=Def|Number=Sing|PronType=Art\t14\tdet\t_\t_\t*\\n\n",
    "14\toifig\toifig\tNOUN\tNoun\tDefinite=Def|Gender=Fem|Number=Sing\t16\tobj\t_\t_\t*\\n\n",
    "15\ta\ta\tPART\tInf\tPartType=Inf\t16\tmark\t_\t_\t*\\n\n",
    "16\triar\triar\tNOUN\tNoun\tVerbForm=Inf\t8\txcomp\t_\t_\t*\\n\n",
    "17\tgo\tgo\tPART\tAd\tPartType=Ad\t18\tmark:prt\t_\t_\t*\\n\n",
    "18\théifeachtach\téifeachtach\tADJ\tAdj\tDegree=Pos|Form=HPref\t16\tadvmod\t_\t_\t*\\n\n",
    "19\tach\tach\tSCONJ\tSubord\t_\t20\tmark\t_\t_\t*\\n\n",
    "20\tchuir\tcuir\tVERB\tVTI\tForm=Len|Mood=Ind|Tense=Past\t8\tadvcl\t_\t_\tVID\\n\n",
    "21\tna\tna\tDET\tArt\tDefinite=Def|Number=Plur|PronType=Art\t22\tdet\t_\t_\t*\\n\n",
    "22\triaráistí\triaráiste\tNOUN\tNoun\tDefinite=Def|Gender=Masc|Number=Plur\t20\tnsubj\t_\t_\t*\\n\n",
    "23\toibre\tobair\tNOUN\tNoun\tCase=Gen|Gender=Fem|Number=Sing\t22\tnmod\t_\t_\t*\\n\n",
    "24\talltacht\talltacht\tNOUN\tNoun\tGender=Fem|Number=Sing\t20\tobj\t_\t_\tVID\\n\n",
    "25\tair\tar\tADP\tPrep\tGender=Masc|Number=Sing|Person=3\t20\tobl:prep\t_\tSpaceAfter=No\t*\\n\n",
    "26\t.\t.\tPUNCT\t.\t_\t8\tpunct\t_\t_\t*\"\"\"\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev.split('\\n')\n",
    "dev = [d for d in dev if d != '']\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prediction = [1, None]\n",
    "verb_found = False\n",
    "for line in dev:\n",
    "    feats = line.split('\\t')\n",
    "    if not line.startswith('#') and line != '\\n' and '-' not in feats[0]:\n",
    "        \n",
    "        if feats[10] == '*':\n",
    "            print(line)\n",
    "        else:\n",
    "\n",
    "            if current_prediction[1] is None:\n",
    "\n",
    "                label = '{}:{}'.format(current_prediction[0], feats[10])\n",
    "                verb_found = True if feats[3] == 'VERB' else False\n",
    "                current_prediction[1] = feats[10]\n",
    "\n",
    "            else:\n",
    "\n",
    "                if feats[10] == current_prediction[1]:\n",
    "\n",
    "                    if verb_found and feats[3] != 'VERB':\n",
    "                        label = current_prediction[0]\n",
    "\n",
    "                    elif verb_found and feats[3] == 'VERB':\n",
    "                        current_prediction[0] = current_prediction[0] + 1\n",
    "                        current_prediction[1] = feats[10]\n",
    "                        label = '{}:{}'.format(current_prediction[0], feats[10])\n",
    "                    \n",
    "                    elif not verb_found:\n",
    "                        label = current_prediction[0]\n",
    "                        verb_found = True if feats[3] == 'VERB' else False\n",
    "\n",
    "                else:\n",
    "                    current_prediction[0] = current_prediction[0] + 1\n",
    "                    current_prediction[1] = feats[10]\n",
    "                    label = '{}:{}'.format(current_prediction[0], feats[10])\n",
    "                    verb_found = True if feats[3] == 'VERB' else False\n",
    "            print('\\t'.join(feats[0:-1] + [str(label)] + ['pred']))\n",
    "    else:\n",
    "        if line == '\\n':\n",
    "            current_prediction = [1, None]\n",
    "            verb_found = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transformer.MWE.CNN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
