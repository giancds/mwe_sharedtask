{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 64813,\n",
      "  \"iopub_port\": 64814,\n",
      "  \"stdin_port\": 64815,\n",
      "  \"control_port\": 64817,\n",
      "  \"hb_port\": 64816,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"71c91fe2-e00fd3d689b744dd38af60df\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-f764f69d-f605-4fd7-8fef-bd5353052127.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = sys.argv[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# from models import CNNClassifier\n",
    "from preprocess import load_tokenized_data#, SentenceDataset, SkorchBucketIterator\n",
    "from utils import build_model_name, convert_flags_to_dict, define_cnn_flags\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset, Field, Example\n",
    "from torchtext.data.iterator import BucketIterator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import ProgressBar, EpochScoring, EarlyStopping, Checkpoint\n",
    "from skorch.callbacks.scoring import ScoringBase\n",
    "from skorch.helper import predefined_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, min_len=5, **kwargs):\n",
    "        self.min_len = min_len\n",
    "        text_field = Field(use_vocab=False, pad_token=0, batch_first=True)\n",
    "        label_field = Field(use_vocab=False, pad_token=0, batch_first=True)\n",
    "        fields = [(\"sentence\", text_field), (\"labels\", label_field)]\n",
    "        examples = []\n",
    "        for (x, y) in zip(data[0], data[1]):\n",
    "            if len(x) < self.min_len:  # pad all sequences shorter than this\n",
    "                x += [0] * (5 - len(x))\n",
    "                y += [0] * (5 - len(y))\n",
    "            examples.append(Example.fromlist([x, y], fields))\n",
    "        super().__init__(examples, fields, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkorchBucketIterator(BucketIterator):\n",
    "    def __iter__(self):\n",
    "        for batch in super().__iter__():\n",
    "            # We make a small modification: Instead of just returning batch\n",
    "            # we return batch.text and batch.label, corresponding to X and y\n",
    "            # if self.train:\n",
    "            y =  batch.labels.to('cpu')\n",
    "            y = to_categorical(y, num_classes=2)#[:, :, 1:]\n",
    "            y = torch.tensor(y).to(self.device)\n",
    "            batch.labels = y\n",
    "            # else:\n",
    "            #     batch.labels = batch.labels.float()\n",
    "            yield batch.sentence, batch.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "\n",
    "        self.transformer_device = config[\"transformer_device\"]\n",
    "        self.model_device = config[\"transformer_device\"]\n",
    "        self.transformer = config[\"bert\"]\n",
    "\n",
    "        self.convolutions = nn.ModuleList([\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.transformer.embeddings.word_embeddings.embedding_dim,\n",
    "                out_channels=config[\"nfilters\"],\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1) for kernel_size in config[\"kernels\"]])\n",
    "\n",
    "        self.pool_stride = config[\"pool_stride\"]\n",
    "\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "        self.fully_connected = nn.Linear(\n",
    "            (config[\"nfilters\"] // config[\"pool_stride\"]) * len(config[\"kernels\"]), 2)\n",
    "\n",
    "        self.output_activation = (torch.sigmoid  # pylint: disable=no-member\n",
    "                                  if config[\"output_activation\"] == 'sigmoid'\n",
    "                                  else F.softmax)\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        self = super().to(*args, **kwargs)\n",
    "        self.transformer = self.transformer.to(\n",
    "            torch.device(self.transformer_device))\n",
    "        self.model_device = next(self.fully_connected.parameters()).device.type\n",
    "        return self\n",
    "\n",
    "    def freeze_transformer(self):\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_transformer(self):\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        m = (x > 0).int()\n",
    "        x = self.transformer(x, attention_mask=m)[0]\n",
    "        #\n",
    "        x = x * m.unsqueeze(2)\n",
    "        x = torch.where(x > 0, x, torch.tensor(-1.0))\n",
    "        x = x.transpose(1, 2)\n",
    "        seq_len = x.shape[-1]\n",
    "        #\n",
    "        if self.transformer_device != self.model_device:\n",
    "            x = x.to(self.model_device)\n",
    "        #\n",
    "        x = [F.relu(conv(x)).transpose(1, 2) for conv in self.convolutions]\n",
    "        x = [nn.functional.pad(i, (0, 0, 0, seq_len - i.shape[1])) for i in x]\n",
    "        x = [F.max_pool1d(c, self.pool_stride) for c in x]\n",
    "        x = torch.cat(x, dim=2)  # pylint: disable=no-member\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.output_activation(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdiomClassifier(NeuralNetClassifier):\n",
    "\n",
    "    def __init__(self, print_report=True, *args, **kwargs):\n",
    "        self.print_report = print_report\n",
    "        super(IdiomClassifier, self).__init__(*args, **kwargs)\n",
    "        self.set_params(callbacks__valid_acc=None)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.module.eval()\n",
    "        return torch.argmax(self.module(X), dim=2)\n",
    "\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        self.module.eval()\n",
    "        ds = self.get_dataset(X)\n",
    "        target_iterator = self.get_iterator(ds, training=False)\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for x, y in target_iterator:\n",
    "            preds = self.predict(x)\n",
    "            y_pred.append(preds.view(-1))\n",
    "            y = torch.argmax(y, dim=2)\n",
    "            y_true.append(y.view(-1))\n",
    "        y_true = torch.cat(y_true).detach().numpy()\n",
    "        y_pred = torch.cat(y_pred).detach().numpy()\n",
    "\n",
    "        if self.print_report:\n",
    "            print(classification_report(y_true, y_pred))\n",
    "        return f1_score(y_true, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScorer(EpochScoring):\n",
    "    def on_epoch_end(self, net, dataset_train, dataset_valid, **kwargs):\n",
    "        current_score = net.score(dataset_valid)\n",
    "        self._record_score(net.history, current_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_type = 'distilbert-base-multilingual-cased'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "METRIC = \"F1\"\n",
    "language_codes = ['DE', 'GA', 'HI', 'PT', 'ZH']\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "228\n",
      "99\n",
      "338\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_dev, y_dev) = load_tokenized_data(\n",
    "    datafile='{}/data/{}.tokenized.pkl'.format(cwd, bert_type),\n",
    "    language_codes=language_codes,\n",
    "    seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(bert_type)\n",
    "transformer = AutoModel.from_pretrained(bert_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'nfilters': 128,\n",
    "    'kernels': [1, 2, 3, 4, 5],\n",
    "    'pool_stride': 3,\n",
    "    'dropout': 0.2,\n",
    "    'output_activation': 'sigmoid',\n",
    "    'transformer_device': 'cpu',\n",
    "    'bert': transformer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNClassifier(config)\n",
    "# model.to(DEVICE)   # pylint: disable=no-member\n",
    "model.freeze_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = IdiomClassifier(\n",
    "    module=model,\n",
    "    #\n",
    "    iterator_train=SkorchBucketIterator,    \n",
    "    iterator_train__batch_size=32,\n",
    "    iterator_train__sort_key=lambda x: len(x.sentence),\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__device=DEVICE,\n",
    "    #\n",
    "    iterator_valid=SkorchBucketIterator, \n",
    "    iterator_valid__batch_size=1,\n",
    "    iterator_valid__sort_key=lambda x: len(x.sentence),\n",
    "    iterator_valid__shuffle=True,\n",
    "    iterator_valid__device=DEVICE,\n",
    "    \n",
    "    train_split=predefined_split(SentenceDataset(data=(x_val[0:10], y_val[0:10]))),\n",
    "            \n",
    "    optimizer=torch.optim.Adam,\n",
    "    \n",
    "    criterion=nn.BCELoss,\n",
    "#     criterion__ignore_index=-1,\n",
    "    \n",
    "    callbacks=[\n",
    "        ProgressBar(batches_per_epoch=len(x_train) // 32 + 1),\n",
    "        CustomScorer(scoring=None, lower_is_better=False, use_caching=False),\n",
    "        EarlyStopping(monitor='score_best', patience=5),\n",
    "        Checkpoint(monitor='score_best')\n",
    "        \n",
    "    ],\n",
    "\n",
    "    device=DEVICE,\n",
    ")\n",
    "# net.set_params(callbacks__valid_acc=None)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('epoch_timer', <skorch.callbacks.logging.EpochTimer at 0x14e77bb90>),\n",
       " ('train_loss', <skorch.callbacks.scoring.PassthroughScoring at 0x14e77bc10>),\n",
       " ('valid_loss', <skorch.callbacks.scoring.PassthroughScoring at 0x14e77bcd0>),\n",
       " ('valid_acc', None),\n",
       " ('ProgressBar', <skorch.callbacks.logging.ProgressBar at 0x14e77b290>),\n",
       " ('CustomScorer', <__main__.CustomScorer at 0x14e77b310>),\n",
       " ('EarlyStopping', <skorch.callbacks.training.EarlyStopping at 0x14e77b990>),\n",
       " ('Checkpoint', <skorch.callbacks.training.Checkpoint at 0x14e77ba10>),\n",
       " ('print_log', <skorch.callbacks.logging.PrintLog at 0x14e77bdd0>)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.callbacks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.fit(SentenceDataset(data=(x_train[0:32], y_train[0:32])), y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x_dev, _y_dev = x_dev['GA'], y_dev['GA']\n",
    "test_iterator = SkorchBucketIterator(\n",
    "    dataset=SentenceDataset(data=(_x_dev, _y_dev)),\n",
    "    batch_size=1,\n",
    "    sort_key=lambda x: len(x.sentence),\n",
    "    shuffle=False,\n",
    "    device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "40\n",
      "80\n",
      "120\n",
      "160\n",
      "200\n",
      "240\n",
      "280\n",
      "320\n",
      "## Global evaluation\n",
      "* MWE-based: P=29/665=0.0436 R=29/126=0.2302 F=0.0733\n",
      "* Tok-based: P=287/7024=0.0409 R=287/287=1.0000 F=0.0785\n",
      "\n",
      "## Per-category evaluation (partition of Global)\n",
      "* IAV: MWE-proportion: gold=42/126=33% pred=17/665=3%\n",
      "* IAV: MWE-based: P=7/17=0.4118 R=7/42=0.1667 F=0.2373\n",
      "* IAV: Tok-based: P=35/95=0.3684 R=35/86=0.4070 F=0.3867\n",
      "* LVC.cause: MWE-proportion: gold=22/126=17% pred=10/665=2%\n",
      "* LVC.cause: MWE-based: P=6/10=0.6000 R=6/22=0.2727 F=0.3750\n",
      "* LVC.cause: Tok-based: P=21/37=0.5676 R=21/49=0.4286 F=0.4884\n",
      "* LVC.full: MWE-proportion: gold=29/126=23% pred=12/665=2%\n",
      "* LVC.full: MWE-based: P=7/12=0.5833 R=7/29=0.2414 F=0.3415\n",
      "* LVC.full: Tok-based: P=26/69=0.3768 R=26/65=0.4000 F=0.3881\n",
      "* <unlabeled>: MWE-proportion: gold=0/126=0% pred=609/665=92%\n",
      "* <unlabeled>: MWE-based: P=0/609=0.0000 R=0/0=0.0000 F=0.0000\n",
      "* <unlabeled>: Tok-based: P=0/6728=0.0000 R=0/0=0.0000 F=0.0000\n",
      "* VID: MWE-proportion: gold=22/126=17% pred=10/665=2%\n",
      "* VID: MWE-based: P=4/10=0.4000 R=4/22=0.1818 F=0.2500\n",
      "* VID: Tok-based: P=30/66=0.4545 R=30/65=0.4615 F=0.4580\n",
      "* VPC.full: MWE-proportion: gold=6/126=5% pred=5/665=1%\n",
      "* VPC.full: MWE-based: P=4/5=0.8000 R=4/6=0.6667 F=0.7273\n",
      "* VPC.full: Tok-based: P=10/15=0.6667 R=10/12=0.8333 F=0.7407\n",
      "* VPC.semi: MWE-proportion: gold=5/126=4% pred=2/665=0%\n",
      "* VPC.semi: MWE-based: P=1/2=0.5000 R=1/5=0.2000 F=0.2857\n",
      "* VPC.semi: Tok-based: P=4/14=0.2857 R=4/10=0.4000 F=0.3333\n",
      "\n",
      "## MWE continuity (partition of Global)\n",
      "* Continuous: MWE-proportion: gold=59/126=47% pred=71/665=11%\n",
      "* Continuous: MWE-based: P=16/71=0.2254 R=16/59=0.2712 F=0.2462\n",
      "* Discontinuous: MWE-proportion: gold=67/126=53% pred=594/665=89%\n",
      "* Discontinuous: MWE-based: P=13/594=0.0219 R=13/67=0.1940 F=0.0393\n",
      "\n",
      "## Number of tokens (partition of Global)\n",
      "* Multi-token: MWE-proportion: gold=126/126=100% pred=643/665=97%\n",
      "* Multi-token: MWE-based: P=29/643=0.0451 R=29/126=0.2302 F=0.0754\n",
      "* Single-token: MWE-proportion: gold=0/126=0% pred=22/665=3%\n",
      "* Single-token: MWE-based: P=0/22=0.0000 R=0/0=0.0000 F=0.0000\n",
      "\n",
      "## Whether seen in train (partition of Global)\n",
      "* Seen-in-train: MWE-proportion: gold=26/126=21% pred=6/665=1%\n",
      "* Seen-in-train: MWE-based: P=6/6=1.0000 R=6/26=0.2308 F=0.3750\n",
      "* Unseen-in-train: MWE-proportion: gold=100/126=79% pred=659/665=99%\n",
      "* Unseen-in-train: MWE-based: P=23/659=0.0349 R=23/100=0.2300 F=0.0606\n",
      "\n",
      "## Whether identical to train (partition of Seen-in-train)\n",
      "* Variant-of-train: MWE-proportion: gold=21/26=81% pred=2/6=33%\n",
      "* Variant-of-train: MWE-based: P=2/2=1.0000 R=2/21=0.0952 F=0.1739\n",
      "* Identical-to-train: MWE-proportion: gold=5/26=19% pred=4/6=67%\n",
      "* Identical-to-train: MWE-based: P=4/4=1.0000 R=4/5=0.8000 F=0.8889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for code in language_codes:\n",
    "    evaluate_model(net, test_iterator, tokenizer, '{}/data/{}/dev.cupt'.format(cwd, code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
