{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 52390,\n",
      "  \"iopub_port\": 52391,\n",
      "  \"stdin_port\": 52392,\n",
      "  \"control_port\": 52394,\n",
      "  \"hb_port\": 52393,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"5d798c61-cd5514b282a7737aff16c012\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-6a8ec14e-e818-44d0-b310-d86d14659c49.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = sys.argv[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from preprocess import Features, load_dataset, pre_process_data\n",
    "from evaluation import MetricsReporterCallback, evaluate\n",
    "from utils import get_callbacks, get_optimizer\n",
    "from utils import define_cnn_flags, build_cnn_name, convert_flags_to_dict\n",
    "from utils import define_rnn_flags, build_model_name\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.integration.keras import TuneReporterCallback\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.suggest import Repeater\n",
    "# from ray.tune.integration.keras import TuneReporterCallback\n",
    "from hyperopt import hp\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if len(gpus) > 0:\n",
    "#     tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "#\n",
    "SEED = 42\n",
    "BASE_DIR = os.path.expanduser(\"~\")     # this will point to the user's home\n",
    "TRAIN_DIR = \"train_mwe_classifier\"\n",
    "\n",
    "# #####\n",
    "# Some hyperparameter definitions\n",
    "#\n",
    "FLAGS = define_rnn_flags(tf.compat.v1.flags, BASE_DIR, TRAIN_DIR)\n",
    "\n",
    "_FEATURE = Features.upos\n",
    "\n",
    "if FLAGS.feature == 'xpos':\n",
    "    _FEATURE = Features.xpos\n",
    "\n",
    "elif FLAGS.feature == 'deprel':\n",
    "    _FEATURE = Features.deprel\n",
    "\n",
    "# model_name = build_model_name('sentlevel', FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n"
     ]
    }
   ],
   "source": [
    "_config = convert_flags_to_dict(FLAGS)\n",
    "_config[\"is_dev\"] = False\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# #####\n",
    "# Loading data\n",
    "#\n",
    "\n",
    "print('Pre-processing data...')\n",
    "\n",
    "# train dataset\n",
    "\n",
    "# train_files = ['data/GA/train.cupt']\n",
    "train_files = [cwd + '/data/GA/train.cupt'] if _config[\"is_dev\"] else []\n",
    "train_sents, train_labels = load_dataset(train_files, feature=_FEATURE)\n",
    "\n",
    "# validation/dev dataset\n",
    "dev_files = [cwd + '/data/GA/dev.cupt'] if _config[\"is_dev\"] else []\n",
    "dev_sents, dev_labels = load_dataset(dev_files, feature=_FEATURE, train=False)\n",
    "\n",
    "train_data, dev_data, (max_len, n_tokens) = pre_process_data(\n",
    "    (train_sents, train_labels), (dev_sents, dev_labels), seed=SEED)\n",
    "\n",
    "_x_train, _x_val, _y_train, _y_val = train_data\n",
    "_x_dev, _y_dev = dev_data\n",
    "\n",
    "_config[\"x_train\"] = _x_train\n",
    "_config[\"x_val\"] = _x_val\n",
    "_config[\"y_train\"] = _y_train\n",
    "_config[\"y_val\"] = _y_val\n",
    "\n",
    "_config[\"x_dev\"] = _x_dev\n",
    "_config[\"y_dev\"] = _y_dev\n",
    "\n",
    "_config[\"n_tokens\"] = n_tokens\n",
    "_config[\"max_len\"] = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \n",
    "    model_name = build_model_name('sentlevel', config)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    # embedding\n",
    "    model.add(\n",
    "        tf.keras.layers.Embedding(\n",
    "            config[\"n_tokens\"] + 1,\n",
    "            config[\"embed_dim\"],\n",
    "            input_length=config[\"max_len\"],\n",
    "            mask_zero=True,\n",
    "            embeddings_initializer=tf.random_uniform_initializer(\n",
    "                minval=-config[\"init_scale\"],\n",
    "                maxval=config[\"init_scale\"],\n",
    "                seed=SEED)))\n",
    "    if config[\"spatial_dropout\"]:\n",
    "        model.add(tf.keras.layers.SpatialDropout1D(config[\"dropout\"]))\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Dropout(config[\"dropout\"]))\n",
    "\n",
    "    # LSTMs\n",
    "    for layer in range(config[\"n_layers\"]):\n",
    "        return_sequences = False if layer == config[\"n_layers\"] - 1 else True\n",
    "        layer = tf.keras.layers.LSTM(\n",
    "            config[\"lstm_size\"],\n",
    "        #  dropout=FLAGS.lstm_dropout,\n",
    "            recurrent_dropout=config[\"lstm_recurrent_dropout\"],\n",
    "            return_sequences=return_sequences,\n",
    "            kernel_initializer=tf.random_uniform_initializer(\n",
    "                minval=-config[\"init_scale\"],\n",
    "                maxval=config[\"init_scale\"],\n",
    "                seed=SEED),\n",
    "            recurrent_initializer=tf.random_uniform_initializer(\n",
    "                minval=-config[\"init_scale\"],\n",
    "                maxval=config[\"init_scale\"],\n",
    "                seed=SEED),\n",
    "        )\n",
    "        # if bidirectional\n",
    "        if config[\"bilstm\"]:\n",
    "            layer = tf.keras.layers.Bidirectional(layer)\n",
    "        model.add(layer)\n",
    "        model.add(tf.keras.layers.Dropout(config[\"lstm_dropout\"]))\n",
    "\n",
    "    if config[\"output_size\"] == 1:\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation='sigmoid',\n",
    "                kernel_initializer=tf.random_uniform_initializer(\n",
    "                    minval=-config[\"init_scale\"],\n",
    "                    maxval=config[\"init_scale\"],\n",
    "                    seed=SEED)))\n",
    "        y_train = config[\"y_train\"]\n",
    "        y_val = config[\"y_val\"]\n",
    "    else:\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                2,\n",
    "                activation=config[\"output_activation\"],\n",
    "                kernel_initializer=tf.random_uniform_initializer(\n",
    "                    minval=-config[\"init_scale\"],\n",
    "                    maxval=config[\"init_scale\"],\n",
    "                    seed=SEED)))\n",
    "        y_train = tf.keras.utils.to_categorical(config[\"y_train\"])\n",
    "        y_val = tf.keras.utils.to_categorical(config[\"y_val\"])\n",
    "\n",
    "    if config[\"optimizer\"] == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam\n",
    "    elif config[\"optimizer\"] == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD\n",
    "\n",
    "    # compiling model\n",
    "    model.compile(loss=config[\"loss_function\"],\n",
    "                  optimizer=optimizer(learning_rate=config[\"learning_rate\"],\n",
    "                                      clipnorm=config[\"clipnorm\"]),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    class_weights = None\n",
    "    if config[\"weighted_loss\"]:\n",
    "        weights = class_weight.compute_class_weight(\n",
    "            'balanced', np.array([0, 1]), np.array([i for i in train_labels]))\n",
    "        class_weights = {}\n",
    "\n",
    "        for i in range(weights.shape[0]):\n",
    "            class_weights[i] = weights[i]\n",
    "\n",
    "    print('Class weights: {}'.format(class_weights))\n",
    "\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(config[\"train_dir\"] +\n",
    "                                                    model_name,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [\n",
    "        MetricsReporterCallback(\n",
    "            custom_validation_data=(config[\"x_val\"], y_val)),\n",
    "        checkpoint]\n",
    "\n",
    "    if config[\"early_stop_patience\"] > 0:\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            min_delta=config[\"early_stop_delta\"],\n",
    "            patience=config[\"early_stop_patience\"])\n",
    "        callbacks.append(early_stop)\n",
    "\n",
    "    if config[\"log_tensorboard\"]:\n",
    "        tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=config[\"train_dir\"] + '/logs')\n",
    "        callbacks.append(tensorboard)\n",
    "\n",
    "    def lr_scheduler(epoch, lr):     # pylint: disable=C0103\n",
    "        lr_decay = config[\"lr_decay\"]**max(epoch - config[\"start_decay\"], 0.0)\n",
    "        return lr * lr_decay\n",
    "\n",
    "    if config[\"start_decay\"] > 0:\n",
    "        lrate = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "        callbacks.append(lrate)\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(config[\"x_train\"],\n",
    "              y_train,\n",
    "              class_weight=class_weights,\n",
    "              batch_size=config[\"batch_size\"],\n",
    "              epochs=config[\"max_epochs\"],\n",
    "              callbacks=callbacks,\n",
    "              verbose=2,\n",
    "              validation_data=(config[\"x_val\"], y_val))\n",
    "\n",
    "    # #####\n",
    "    # Evaluation time\n",
    "    #\n",
    "    evaluate(model, test_data=(config[\"x_dev\"], config[\"y_dev\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"embed_dim\":\n",
    "        hp.choice(\"embed_dim\", [10, 20, 30, 50, 75, 100]),\n",
    "    \"emb_dropout\":\n",
    "        hp.uniform(\"emb_dropout\", 0.0, 0.9),\n",
    "    \"dropout\":\n",
    "        hp.uniform(\"dropout\", 0.0, 0.9),\n",
    "    \"lstm_dropout\":\n",
    "        hp.uniform(\"lstm_dropout\", 0.0, 0.9),\n",
    "    \"lstm_recurrent_dropout\":\n",
    "        hp.uniform(\"lstm_recurrent_dropout\", 0.0, 0.9),\n",
    "    \"bilstm\":\n",
    "        hp.choice(\"bilstm\", [True, False]),\n",
    "    \"spatial_dropout\":\n",
    "        hp.choice(\"spatial_dropout\", [True, False]),\n",
    "    \"init_scale\":\n",
    "        hp.loguniform(\"init_scale\", np.log(1e-2), np.log(1e-1)),\n",
    "    \"n_layers\":\n",
    "        hp.choice(\"n_layers\", [1, 2, 3, 4]),\n",
    "    \"lstm_size\":\n",
    "        hp.choice(\"lstm_size\", [50, 100, 150, 200, 250, 500]),\n",
    "    \"max_epochs\":\n",
    "        hp.choice(\"max_epochs\", [30, 50, 70]),\n",
    "    \"early_stop_delta\":\n",
    "        hp.choice(\"early_stop_delta\", [0.001, 0.0001]),\n",
    "    \"early_stop_patience\":\n",
    "        hp.choice(\"early_stop_patience\", [10, 20]),\n",
    "    \"output_activation\":\n",
    "        hp.choice(\"output_activation\", ['sigmoid', 'softmax']),\n",
    "    \"feature\":\n",
    "        hp.choice(\"feature\", [\"upos\", \"deprel\"]),\n",
    "    \"clipnorm\":\n",
    "        hp.choice(\"clipnorm\", [0.5, 1.0, 2.5, 5.0, 10.0]),\n",
    "    \"learning_rate\":\n",
    "        hp.loguniform(\"learning_rate\", np.log(1e-4), np.log(1e-0)),\n",
    "    \"optimizer\":\n",
    "        hp.choice(\"optimizer\", ['adam', 'rmsprop']),\n",
    "    \"batch_size\":\n",
    "        hp.choice(\"batch_size\", [20, 24, 32, 64, 128]),\n",
    "}\n",
    "\n",
    "\n",
    "_config.update({\n",
    "    \"threads\": 1,\n",
    "    \"output_size\": 2,\n",
    "    \"start_decay\": 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-23 15:01:11,064\tINFO resource_spec.py:212 -- Starting Ray with 2.2 GiB memory available for workers and up to 1.11 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-05-23 15:01:11,577\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.15.3',\n",
       " 'raylet_ip_address': '192.168.15.3',\n",
       " 'redis_address': '192.168.15.3:64080',\n",
       " 'object_store_address': '/tmp/ray/session_2020-05-23_15-01-11_003831_10909/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-05-23_15-01-11_003831_10909/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-05-23_15-01-11_003831_10909'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()     # Restart Ray defensively in case the ray connection is lost.\n",
    "ray.init(num_cpus=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.0/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 320.000: None | Iter 80.000: None | Iter 20.000: None<br>Resources requested: 2/3 CPUs, 0/0 GPUs, 0.0/2.2 GiB heap, 0.0/0.73 GiB objects<br>Result logdir: /Users/gian/ray_results/tune-rnn<br>Number of trials: 2 (1 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th>bilstm  </th><th style=\"text-align: right;\">  clipnorm</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  early_stop_delta</th><th style=\"text-align: right;\">  early_stop_patience</th><th style=\"text-align: right;\">  emb_dropout</th><th style=\"text-align: right;\">  embed_dim</th><th>feature  </th><th style=\"text-align: right;\">  init_scale</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  lstm_dropout</th><th style=\"text-align: right;\">  lstm_recurrent_dropout</th><th style=\"text-align: right;\">  lstm_size</th><th style=\"text-align: right;\">  max_epochs</th><th style=\"text-align: right;\">  n_layers</th><th>optimizer  </th><th>output_activation  </th><th>spatial_dropout  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_633f9812</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">          32</td><td>True    </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\"> 0.1     </td><td style=\"text-align: right;\">             0.001</td><td style=\"text-align: right;\">                   10</td><td style=\"text-align: right;\">     0.1     </td><td style=\"text-align: right;\">         30</td><td>upos     </td><td style=\"text-align: right;\">    0.05    </td><td style=\"text-align: right;\">     0.0001    </td><td style=\"text-align: right;\">      0.2     </td><td style=\"text-align: right;\">                0       </td><td style=\"text-align: right;\">        200</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">         1</td><td>rmsprop    </td><td>sigmoid            </td><td>True             </td></tr>\n",
       "<tr><td>train_model_6386513a</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          64</td><td>True    </td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\"> 0.314161</td><td style=\"text-align: right;\">             0.001</td><td style=\"text-align: right;\">                   10</td><td style=\"text-align: right;\">     0.158599</td><td style=\"text-align: right;\">         75</td><td>deprel   </td><td style=\"text-align: right;\">    0.016309</td><td style=\"text-align: right;\">     0.00155972</td><td style=\"text-align: right;\">      0.436668</td><td style=\"text-align: right;\">                0.287503</td><td style=\"text-align: right;\">        150</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">         3</td><td>adam       </td><td>softmax            </td><td>False            </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m Model name 0.05_sentlevel_50epochs.10-0.001eStop.30embDim.0.1-spatial-dropout.1-200-bi-lstm.0.2lstmDrop.0.0lstmRecDrop.2-sigmoid.binary_crossentropyLoss.32batch.rmsprop.0.0001lr.0.8695652173913044-0decay.1.0norm.0.05initScale.ckpt\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m 2020-05-23 15:01:25,978\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m 2020-05-23 15:01:26.010787: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m 2020-05-23 15:01:26.052422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa75c765f70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m 2020-05-23 15:01:26.052468: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m Model: \"sequential\"\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m embedding (Embedding)        (None, 242, 30)           2340      \n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m spatial_dropout1d (SpatialDr (None, 242, 30)           0         \n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m bidirectional (Bidirectional (None, 400)               369600    \n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m dropout (Dropout)            (None, 400)               0         \n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m dense (Dense)                (None, 2)                 802       \n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m =================================================================\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m Total params: 372,742\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m Trainable params: 372,742\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m Non-trainable params: 0\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m _________________________________________________________________\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m None\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m Class weights: {0: 0.6251696320868516, 1: 2.4972895648245745}\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m Train...\n",
      "\u001b[2m\u001b[36m(pid=11070)\u001b[0m Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9f91a72327b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             }]),\n\u001b[0;32m---> 50\u001b[0;31m     verbose=1,)\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, concurrent)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mtrial_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             return_trials=True)\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         )\n\u001b[1;32m   1650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = tune.run_experiments(\n",
    "    tune.Experiment(\n",
    "        run=train_model,        \n",
    "        name=\"tune-rnn\",\n",
    "        config=_config,\n",
    "         stop={\n",
    "            \"keras_info/label1_f1_score\": 0.9,\n",
    "            \"training_iteration\": 10**8\n",
    "        },\n",
    "        resources_per_trial={\n",
    "            \"cpu\": 2,\n",
    "            \"gpu\": 0\n",
    "        },\n",
    "        num_samples=2,\n",
    "        checkpoint_freq=0,\n",
    "        checkpoint_at_end=False),\n",
    "    scheduler=AsyncHyperBandScheduler(\n",
    "        time_attr=\"epoch\",\n",
    "        metric=\"keras_info/label1_f1_score\",\n",
    "        mode=\"max\",\n",
    "        max_t=400,\n",
    "        grace_period=20),\n",
    "    search_alg=HyperOptSearch(\n",
    "            search_space,\n",
    "            metric=\"keras_info/label1_f1_score\",\n",
    "            mode=\"max\",\n",
    "            random_state_seed=SEED,\n",
    "            points_to_evaluate=[{\n",
    "                \"embed_dim\": 2,\n",
    "                \"emb_dropout\": 0.1,\n",
    "                \"dropout\": 0.1,\n",
    "                \"lstm_dropout\": 0.2,\n",
    "                \"lstm_recurrent_dropout\": 0.0,     \n",
    "                \"bilstm\": 1,\n",
    "                \"spatial_dropout\": 0,\n",
    "                \"init_scale\": 0.05,\n",
    "                \"n_layers\": 0,\n",
    "                \"lstm_size\": 1,\n",
    "                \"max_epochs\": 1,\n",
    "                \"early_stop_delta\": 0,\n",
    "                \"early_stop_patience\": 0,\n",
    "                \"optimizer\": 1,\n",
    "                \"output_activation\": 0,\n",
    "                \"feature\":  0,\n",
    "                \"clipnorm\": 1,\n",
    "                \"learning_rate\": 0.0001,\n",
    "                \"optimizer\": 0,\n",
    "                \"batch_size\": 2,\n",
    "            }]),\n",
    "    verbose=1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dataframe().to_csv(_config[\"train_dir\"] + '/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2087"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
