{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.MWE.CNN-RNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iduyUpQLMQu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f792f6c0-f476-4de5-92a7-8dd46dffb997"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaOrLp1V7Thq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "9d31ce7d-aa37-4f63-d866-a6f8099cf4cb"
      },
      "source": [
        "!pip install skorch transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.15.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4EcbeP-7F94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_DGhaUSB0mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.argv = sys.argv[:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEM3NMSb7gpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import skorch\n",
        "from skorch import NeuralNetClassifier\n",
        "from skorch.callbacks import ProgressBar, EarlyStopping, Checkpoint\n",
        "from skorch.helper import predefined_split\n",
        "from torchtext.data import Dataset, Field, Example, BucketIterator\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "from evaluation import evaluate_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7frPRyDGEbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from eval_scripts.evaluate import Main\n",
        "\n",
        "def evaluate_model(net, test_iterator, tokenizer, args):\n",
        "    preds = []\n",
        "    sents = []\n",
        "    i = 0\n",
        "    for x, y in test_iterator:\n",
        "        y_pred = net.predict(x)\n",
        "    #     i += 1\n",
        "        if i % 40 == 0:\n",
        "            print(i)\n",
        "        i += 1\n",
        "        sub_tokens = []\n",
        "        sub_preds = []\n",
        "        text = []\n",
        "        predictions = []\n",
        "        tokens = tokenizer.convert_ids_to_tokens(x.detach().cpu().numpy().reshape(-1))\n",
        "        # tokens = tokens\n",
        "        y_pred = y_pred.cpu().detach().reshape(-1).tolist()\n",
        "        for t, p in zip(tokens, y_pred):\n",
        "            if '#' in t:\n",
        "                sub_tokens.append(t.replace('#', ''))\n",
        "                sub_preds.append(p)\n",
        "            else:\n",
        "                if sub_tokens:\n",
        "                    old_token = ''.join([text[-1]] + sub_tokens)\n",
        "                    old_pred = sum(sub_preds)\n",
        "                    text = text[0:-1]\n",
        "                    text.append(old_token)\n",
        "                    predictions = predictions[0:-1]\n",
        "                    predictions.append(old_pred if old_pred == 0 else 1)\n",
        "                    old_token = t\n",
        "                    old_pred = p\n",
        "                    sub_tokens = []\n",
        "                    sub_preds = []\n",
        "                else:\n",
        "                    old_token = t\n",
        "                    old_pred = p\n",
        "                text.append(old_token)\n",
        "                predictions.append(old_pred)\n",
        "                assert len(text[1:-1]) == len(predictions[1:-1])\n",
        "        sents.append(text[1:-1])\n",
        "        preds += predictions[1:-1]\n",
        "\n",
        "    output_count = 0\n",
        "    with open(args.dev_file, 'r') as dev:\n",
        "        with open(args.dev_file.replace('dev.cupt', 'system.cupt'), 'w') as test:\n",
        "            for line in dev:\n",
        "                feats = line.split()\n",
        "                if not line.startswith('#') and line is not '\\n' and '-' not in feats[0]:\n",
        "                    test.write(line.replace('*', str(preds[output_count])))\n",
        "                    output_count += 1\n",
        "                else:\n",
        "                    test.write(line)\n",
        "\n",
        "    _run_sript(args)\n",
        "\n",
        "def _run_sript(args):\n",
        "\n",
        "    args.debug = False\n",
        "    args.combinatorial = True\n",
        "    args.gold_file = open(args.dev_file, 'r')\n",
        "    args.prediction_file = open(args.dev_file.replace('dev.cupt', 'system.cupt'), 'r')\n",
        "    args.train_file = open(args.dev_file.replace('dev.cupt', 'train.cupt'), 'r')\n",
        "\n",
        "    Main(args).run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af-eSpyXFM45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_tokenized_data(datafile, language_codes, percent=1.00, seed=42):\n",
        "\n",
        "    with open(datafile, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    x_train, y_train = [], []\n",
        "    x_val, y_val = [], []\n",
        "    x_dev, y_dev = {}, {}\n",
        "    for code in language_codes:\n",
        "\n",
        "        true_x, true_y = [], []\n",
        "        false_x, false_y = [], []\n",
        "        for xsample, ysample in zip(data[code]['x_train'], data[code]['y_train']):\n",
        "            if 1 in ysample:\n",
        "                true_x.append(xsample)\n",
        "                true_y.append(ysample)\n",
        "\n",
        "\n",
        "        max_len = max([len(y) for y in true_y])\n",
        "        for xsample, ysample in zip(data[code]['x_train'], data[code]['y_train']):\n",
        "            if 1 not in ysample and len(ysample) < max_len:\n",
        "                false_x.append(xsample)\n",
        "                false_y.append(ysample)\n",
        "\n",
        "        false_x = np.array(false_x)\n",
        "        false_y = np.array(false_y)\n",
        "\n",
        "        np.random.seed(seed)\n",
        "        idx = np.random.randint(len(false_y), size=int(percent * len(true_y)))\n",
        "        false_x = false_x[idx].tolist()\n",
        "        false_y = false_y[idx].tolist()\n",
        "\n",
        "        x_train += true_x + false_x\n",
        "        y_train += true_y + false_y\n",
        "        x_val += data[code][\"x_dev\"]\n",
        "        y_val += data[code][\"y_dev\"]\n",
        "\n",
        "        x_dev[code] = data[code][\"x_dev\"]\n",
        "        y_dev[code] = data[code][\"y_dev\"]\n",
        "\n",
        "    del data\n",
        "\n",
        "    return (x_train, y_train),( x_val, y_val), (x_dev, y_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecaCoKGYFsEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_name(args, model='rnn-cnn'):\n",
        "    name = ''\n",
        "    if model == 'rnn':\n",
        "        name = (\"{0}.{1}.{2}layers.{3}lstm.{4}dropout.{5}init.{6}activation\"\n",
        "                \"{7}clipnorm.{8}batch.{9}epochs\".format(\n",
        "                    args.bert_type, args.metric, args.nlayers, args.lstm_size,\n",
        "                    args.dropout, args.initrange, args.output_activation,\n",
        "                    args.clipnorm, args.batch_size, args.max_epochs\n",
        "                ))\n",
        "    elif model == 'cnn':\n",
        "        name = (\"{0}.{1}.{2}filters.{3}kernels.{4}poolstride.{5}dropout.\"\n",
        "                \"{6}activation.{7}batch.{8}epochs\".format(\n",
        "                    args.bert_type, args.metric, args.nfilters, args.kernels,\n",
        "                    args.pool_stride, args.dropout, args.output_activation,\n",
        "                    args.batch_size, args.max_epochs\n",
        "                ))\n",
        "    elif model == 'cnn-rnn':\n",
        "         name = (\"{0}.{1}.{2}filters.{3}kernels.{4}poolstride.{5}layers.\"\n",
        "                \"{6}lstm.{7}dropout.{8}init.{9}activation.{10}batch.\"\n",
        "                \"{11}epochs\".format(\n",
        "                    args.bert_type, args.metric, args.nfilters, args.kernels,\n",
        "                    args.pool_stride, args.nlayers, args.lstm_size, args.dropout, \n",
        "                    args.initrange, args.output_activation, args.batch_size, \n",
        "                    args.max_epochs\n",
        "                ))\n",
        "    return name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGpej-dKE5Nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SkorchBucketIterator(BucketIterator):\n",
        "\n",
        "    def __init__(self,\n",
        "                 dataset,\n",
        "                 batch_size,\n",
        "                 sort_key=None,\n",
        "                 device=None,\n",
        "                 batch_size_fn=None,\n",
        "                 train=True,\n",
        "                 repeat=False,\n",
        "                 shuffle=None,\n",
        "                 sort=None,\n",
        "                 sort_within_batch=None,\n",
        "                 one_hot=True):\n",
        "        self.one_hot = one_hot\n",
        "        super(SkorchBucketIterator,\n",
        "              self).__init__(dataset, batch_size, sort_key, device,\n",
        "                             batch_size_fn, train, repeat, shuffle, sort,\n",
        "                             sort_within_batch)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch in super().__iter__():\n",
        "            # We make a small modification: Instead of just returning batch\n",
        "            # we return batch.text and batch.label, corresponding to X and y\n",
        "            # if self.train:\n",
        "            if self.one_hot:\n",
        "                y = batch.labels.to('cpu')\n",
        "                y = to_categorical(y, num_classes=2)\n",
        "                y = torch.tensor(y).to(self.device)\n",
        "                batch.labels = y\n",
        "            else:\n",
        "                batch.labels = batch.labels.float()\n",
        "            yield batch.sentence, batch.labels\n",
        "\n",
        "\n",
        "class SentenceDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, min_len=5, **kwargs):\n",
        "        self.min_len = min_len\n",
        "        text_field = Field(use_vocab=False, pad_token=0, batch_first=True)\n",
        "        label_field = Field(use_vocab=False, pad_token=-1, batch_first=True)\n",
        "        fields = [(\"sentence\", text_field), (\"labels\", label_field)]\n",
        "        examples = []\n",
        "        for (x, y) in zip(data[0], data[1]):\n",
        "            if len(x) < self.min_len:     # pad all sequences shorter than this\n",
        "                x += [0] * (5 - len(x))\n",
        "                y += [-1] * (5 - len(y))\n",
        "            examples.append(Example.fromlist([x, y], fields))\n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "\n",
        "class IdiomClassifier(skorch.NeuralNetClassifier):\n",
        "\n",
        "    def __init__(self, print_report=True, class_weights=None, *args, **kwargs):\n",
        "        self.print_report = print_report\n",
        "        self.class_weights = class_weights\n",
        "        if class_weights is None:\n",
        "            self.class_weights = [1.0, 1.0]\n",
        "        super(IdiomClassifier, self).__init__(*args, **kwargs)\n",
        "        self.set_params(callbacks__valid_acc=None)\n",
        "        self.set_params(criterion__reduction='none')\n",
        "\n",
        "    def get_loss(self, y_pred, y_true, X, *args, **kwargs):\n",
        "        loss = super().get_loss(y_pred.view(-1), y_true.view(-1), X, *args,\n",
        "                                **kwargs)\n",
        "        weights = torch.ones_like(y_true) * y_true\n",
        "        weights = torch.where(\n",
        "            y_true == 0,\n",
        "            torch.tensor(self.class_weights[0]).float().to(self.device),\n",
        "            torch.where(y_true == 1,\n",
        "                        torch.tensor(self.class_weights[1]).to(self.device).float(),\n",
        "                        torch.tensor(-1.0).to(self.device)))\n",
        "        loss = (loss * weights.view(-1))\n",
        "        mask = (y_true >= 0).int()\n",
        "        loss = (loss * mask.view(-1)).mean()\n",
        "        return loss\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.module.eval()\n",
        "        y_pred = self.module(X)\n",
        "        if len(y_pred.shape) > 2:\n",
        "            y_pred = torch.argmax(y_pred, dim=2)\n",
        "        else:\n",
        "            y_pred = (y_pred > 0.5).int()\n",
        "        return y_pred\n",
        "\n",
        "    def score(self, X, y=None):\n",
        "        self.module.eval()\n",
        "        ds = self.get_dataset(X)\n",
        "        target_iterator = self.get_iterator(ds, training=False)\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for x, y in target_iterator:\n",
        "            preds = self.predict(x)\n",
        "            y_pred.append(preds.view(-1))\n",
        "            if len(y.shape) > 2:\n",
        "                y = torch.argmax(y, dim=2)\n",
        "            y_true.append(y.view(-1))\n",
        "        y_true = torch.cat(y_true).cpu().view(-1).detach().numpy().tolist()\n",
        "        y_pred = torch.cat(y_pred).cpu().view(-1).detach().numpy().tolist()\n",
        "\n",
        "        tt, tp = [], []\n",
        "        for t, p in zip(y_true, y_pred):\n",
        "            if t >= 0:\n",
        "                tt.append(t)\n",
        "                tp.append(p)\n",
        "\n",
        "        y_true = tt\n",
        "        y_pred = tp\n",
        "\n",
        "        if self.print_report:\n",
        "            print('Confusion matrix')\n",
        "            print(confusion_matrix(y_true, y_pred))\n",
        "            print(classification_report(y_true, y_pred))\n",
        "        return f1_score(y_true, y_pred, average='binary')\n",
        "\n",
        "\n",
        "class CustomScorer(skorch.callbacks.EpochScoring):\n",
        "\n",
        "    def on_epoch_end(self, net, dataset_train, dataset_valid, **kwargs):\n",
        "        current_score = net.score(dataset_valid)\n",
        "        self._record_score(net.history, current_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvcm3d6JFdp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, config, transformer, transformer_device):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "\n",
        "        self.transformer_device = transformer_device\n",
        "        self.model_device = transformer_device\n",
        "        self.transformer = transformer\n",
        "        self.convolutions = nn.ModuleList([\n",
        "            nn.Conv1d(\n",
        "                in_channels=transformer.embeddings.word_embeddings.embedding_dim,\n",
        "                out_channels=config.nfilters,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=1) for kernel_size in config.kernels])\n",
        "\n",
        "        self.pool_stride = config.pool_stride\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "        ninputs = (config.nfilters // config.pool_stride) * len(config.kernels)\n",
        "        noutputs = (1 if config.output_activation == 'sigmoid' else 2)\n",
        "\n",
        "        self.fully_connected = nn.Linear(ninputs, noutputs)\n",
        "\n",
        "        self.output_activation = (torch.sigmoid  # pylint: disable=no-member\n",
        "                                  if noutputs == 1\n",
        "                                  else F.softmax)\n",
        "\n",
        "    def to(self, *args, **kwargs):\n",
        "        self = super().to(*args, **kwargs)\n",
        "        self.transformer = self.transformer.to(\n",
        "            torch.device(self.transformer_device))\n",
        "        self.model_device = next(self.fully_connected.parameters()).device.type\n",
        "        return self\n",
        "\n",
        "    def freeze_transformer(self):\n",
        "        for param in self.transformer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def unfreeze_transformer(self):\n",
        "        for param in self.transformer.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.transformer_device)\n",
        "        m = (x > 0).int()\n",
        "        x = self.transformer(x, attention_mask=m)[0].transpose(1, 2)\n",
        "        #\n",
        "        seq_len = x.shape[-1]\n",
        "        #\n",
        "        if self.transformer_device != self.model_device:\n",
        "            x = x.to(self.model_device)\n",
        "        #\n",
        "        x = [F.relu(conv(x)).transpose(1, 2) for conv in self.convolutions]\n",
        "        x = [nn.functional.pad(i, (0, 0, 0, seq_len - i.shape[1])) for i in x]\n",
        "        x = [F.max_pool1d(c, self.pool_stride) for c in x]\n",
        "        x = torch.cat(x, dim=2)  # pylint: disable=no-member\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return self.output_activation(x).squeeze()\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, config, transformer, transformer_device):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "\n",
        "        self.transformer_device = transformer_device\n",
        "        self.model_device = transformer_device\n",
        "        self.transformer = transformer\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=transformer.embeddings.word_embeddings.embedding_dim,\n",
        "            hidden_size=config.lstm_size,\n",
        "            num_layers=config.nlayers,\n",
        "            batch_first=True,\n",
        "            dropout=config.dropout)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        noutputs = (1 if config.output_activation == 'sigmoid' else 2)\n",
        "\n",
        "        self.fully_connected = nn.Linear(config.lstm_size, noutputs)\n",
        "\n",
        "        self.output_activation = (torch.sigmoid  # pylint: disable=no-member\n",
        "                                  if noutputs == 1\n",
        "                                  else F.softmax)\n",
        "        self.init_weights(config.initrange)\n",
        "\n",
        "    def to(self, *args, **kwargs):\n",
        "        self = super().to(*args, **kwargs)\n",
        "        self.transformer = self.transformer.to(\n",
        "            torch.device(self.transformer_device))\n",
        "        self.model_device = next(self.fully_connected.parameters()).device.type\n",
        "        return self\n",
        "\n",
        "    def freeze_transformer(self):\n",
        "        for param in self.transformer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def unfreeze_transformer(self):\n",
        "        for param in self.transformer.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.transformer_device)\n",
        "        m = (x > 0).int()\n",
        "        x = self.transformer(x, attention_mask=m)[0]\n",
        "        #\n",
        "        seq_len = x.shape[-1]\n",
        "        #\n",
        "        if self.transformer_device != self.model_device:\n",
        "            x = x.to(self.model_device)\n",
        "        #\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fully_connected(x)\n",
        "\n",
        "        return self.output_activation(x).squeeze()\n",
        "\n",
        "    def init_weights(self, initrange):\n",
        "        for names in self.lstm._all_weights:\n",
        "            for name in filter(lambda n: \"bias\" in n, names):\n",
        "                bias = getattr(self.lstm, name)\n",
        "                n = bias.size(0)\n",
        "                start, end = n//4, n//2\n",
        "                bias.data[start:end].fill_(1.)\n",
        "            for name in filter(lambda n: \"weight\" in n,  names):\n",
        "                weight = getattr(self.lstm, name)\n",
        "                weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "        self.fully_connected.bias.data.fill_(0)\n",
        "        self.fully_connected.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "\n",
        "class CNNRNNClassifier(nn.Module):\n",
        "    def __init__(self, config, transformer, transformer_device):\n",
        "        super(CNNRNNClassifier, self).__init__()\n",
        "\n",
        "        self.transformer_device = transformer_device\n",
        "        self.model_device = transformer_device\n",
        "        self.transformer = transformer\n",
        "\n",
        "        self.convolutions = nn.ModuleList([\n",
        "            nn.Conv1d(\n",
        "                in_channels=transformer.embeddings.word_embeddings.embedding_dim,\n",
        "                out_channels=config.nfilters,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=1) for kernel_size in config.kernels])\n",
        "\n",
        "        self.pool_stride = config.pool_stride\n",
        "\n",
        "        ninputs = (config.nfilters // config.pool_stride) * len(config.kernels)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=ninputs,\n",
        "            hidden_size=config.lstm_size,\n",
        "            num_layers=config.nlayers,\n",
        "            batch_first=True,\n",
        "            dropout=config.dropout)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "        noutputs = (1 if config.output_activation == 'sigmoid' else 2)\n",
        "        self.fully_connected = nn.Linear(config.lstm_size, noutputs)\n",
        "\n",
        "        self.output_activation = (torch.sigmoid  # pylint: disable=no-member\n",
        "                                  if noutputs == 1\n",
        "                                  else F.softmax)\n",
        "        self.init_weights(config.initrange)\n",
        "\n",
        "    def to(self, *args, **kwargs):\n",
        "        self = super().to(*args, **kwargs)\n",
        "        self.transformer = self.transformer.to(\n",
        "            torch.device(self.transformer_device))\n",
        "        self.model_device = next(self.fully_connected.parameters()).device.type\n",
        "        return self\n",
        "\n",
        "    def freeze_transformer(self):\n",
        "        for param in self.transformer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def unfreeze_transformer(self):\n",
        "        for param in self.transformer.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.transformer_device)\n",
        "        m = (x > 0).int()\n",
        "        x = self.transformer(x, attention_mask=m)[0].transpose(1, 2)\n",
        "        #\n",
        "        seq_len = x.shape[-1]\n",
        "        if self.transformer_device != self.model_device:\n",
        "            x = x.to(self.model_device)\n",
        "        #\n",
        "        x = [F.relu(conv(x)).transpose(1, 2) for conv in self.convolutions]\n",
        "        x = [nn.functional.pad(i, (0, 0, 0, seq_len - i.shape[1])) for i in x]\n",
        "        x = [F.max_pool1d(c, self.pool_stride) for c in x]\n",
        "        x = torch.cat(x, dim=2)  # pylint: disable=no-member\n",
        "        x = self.dropout(x)\n",
        "        #\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.dropout(x)\n",
        "        #\n",
        "        x = self.fully_connected(x)\n",
        "        #\n",
        "        return self.output_activation(x).squeeze()\n",
        "\n",
        "    def init_weights(self, initrange):\n",
        "        # for names in self.lstm._all_weights:\n",
        "        #     for name in filter(lambda n: \"bias\" in n, names):\n",
        "        #         bias = getattr(self.lstm, name)\n",
        "        #         n = bias.size(0)\n",
        "        #         start, end = n//4, n//2\n",
        "        #         bias.data[start:end].fill_(1.)\n",
        "        #     for name in filter(lambda n: \"weight\" in n,  names):\n",
        "        #         weight = getattr(self.lstm, name)\n",
        "        #         weight.data.uniform_(-initrange, initrange)\n",
        "        pass\n",
        "        # self.fully_connected.bias.data.fill_(0)\n",
        "        # self.fully_connected.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NIPFLxs7grp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')     # pylint: disable=no-member\n",
        "LANGUAGE_CODES = ['DE', 'GA', 'HI', 'PT', 'ZH']\n",
        "CWD = os.getcwd()\n",
        "BASE_DIR = ''     # this will point to the user's home\n",
        "TRAIN_DIR = \"transformer/cnn\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KMyS3WM7g5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9465e4b4-59c8-4776-fc12-f70779312911"
      },
      "source": [
        "\n",
        "parser = argparse.ArgumentParser(description='Classifier using CNNs')\n",
        "parser.add_argument(\n",
        "    '--bert_type',\n",
        "    type=str,\n",
        "    default='distilbert-base-multilingual-cased',\n",
        "    help='transormer model [should be a miltilingual model]')\n",
        "parser.add_argument(\n",
        "    '--bert_device',\n",
        "    type=str,\n",
        "    default='gpu',\n",
        "    help='device to run the transformer model')\n",
        "parser.add_argument(\n",
        "    '--metric',\n",
        "    type=str,\n",
        "    default='f1',\n",
        "    help='sklearn metric to evaluate the model while training')\n",
        "parser.add_argument(\n",
        "    '--nfilters',\n",
        "    type=int,\n",
        "    default=128,\n",
        "    help='number of convolution filters')\n",
        "parser.add_argument(\n",
        "    '--kernels',\n",
        "    type=list,\n",
        "    default=[1, 2, 3, 4, 5],\n",
        "    help='number of convolution filters')\n",
        "parser.add_argument(\n",
        "    '--pool_stride',\n",
        "    type=int,\n",
        "    default=5,\n",
        "    help='size of the stride for the pooling operation')\n",
        "parser.add_argument(\n",
        "    '--nlayers',\n",
        "    type=int,\n",
        "    default=1,\n",
        "    help='number of convolution filters')\n",
        "parser.add_argument(\n",
        "    '--lstm_size',\n",
        "    type=int,\n",
        "    default=100,\n",
        "    help='number of convolution filters')\n",
        "parser.add_argument(\n",
        "    '--dropout',\n",
        "    type=float,\n",
        "    default=0.2,\n",
        "    help='dropout probability for the dense layer')\n",
        "parser.add_argument(\n",
        "    '--initrange',\n",
        "    type=float,\n",
        "    default=0.1,\n",
        "    help='range to initialize the lstm layers')\n",
        "parser.add_argument(\n",
        "    '--clipnorm',\n",
        "    type=float,\n",
        "    default=1.0,\n",
        "    help='limit to clip the l2 norm of gradients')\n",
        "parser.add_argument(\n",
        "    '--output_activation',\n",
        "    type=str,\n",
        "    default='sigmoid',\n",
        "    help='output activation')\n",
        "parser.add_argument(\n",
        "    '--batch_size',\n",
        "    type=int,\n",
        "    default=32,\n",
        "    help='training batch size')\n",
        "parser.add_argument(\n",
        "    '--eval_batch_size',\n",
        "    type=int,\n",
        "    default=256,\n",
        "    help='validation/evaluation batch size')\n",
        "parser.add_argument(\n",
        "    '--max_epochs',\n",
        "    type=int,\n",
        "    default=100,\n",
        "    help='max number of epochs to train the model')\n",
        "parser.add_argument(\n",
        "    \"--train_dir\",\n",
        "    type=str,\n",
        "    default=os.path.join(BASE_DIR, TRAIN_DIR) + \"/\",\n",
        "    help=\"Train dir\")\n",
        "parser.add_argument(\n",
        "    \"--eval\",\n",
        "    action=\"store_true\",\n",
        "    help=\"eval at the end of the training process\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--eval'], dest='eval', nargs=0, const=True, default=False, type=None, choices=None, help='eval at the end of the training process', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iVJ5HpK7hC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "932598e6-67a4-45af-99e5-c78b69ec8a66"
      },
      "source": [
        "args = parser.parse_args()\n",
        "args.kernels = [int(i) for i in args.kernels if ',' not in str(i)]\n",
        "transformer_device = torch.device(\n",
        "    'cuda' if torch.cuda.is_available() and args.bert_device == 'gpu'\n",
        "    else 'cpu')\n",
        "transformer_device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtYM8yfG7g25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_val, y_val), (x_dev, y_dev) = load_tokenized_data(\n",
        "    datafile='/content/gdrive/My Drive/mwe_sharedtask/data/{}.tokenized.pkl'.format(args.bert_type),\n",
        "    language_codes=LANGUAGE_CODES, percent=1.0,\n",
        "    seed=SEED)\n",
        "\n",
        "targets = np.concatenate(y_train).reshape(-1)\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                     classes=np.unique(targets),\n",
        "                                     y=targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1zspe5Z7g15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(args.bert_type)\n",
        "transformer = AutoModel.from_pretrained(args.bert_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB79j7xQ7g01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9be70d10-8866-4328-bb69-2a84a270559b"
      },
      "source": [
        "model = CNNRNNClassifier(args, transformer, transformer_device)\n",
        "model_name = build_model_name(args, model='cnn-rnn')\n",
        "model.to(DEVICE)     # pylint: disable=no-member\n",
        "model.freeze_transformer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OgdFwcZLdcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "progress_bar = ProgressBar(batches_per_epoch=len(x_train) // args.batch_size + 1)\n",
        "scorer = CustomScorer(scoring=None, name=\"F1\", lower_is_better=False, use_caching=False)\n",
        "early_stopping =  EarlyStopping(monitor='F1', patience=20, lower_is_better=False)\n",
        "checkpoint = Checkpoint(\n",
        "    monitor='F1_best',\n",
        "    dirname=args.train_dir,\n",
        "    f_params='{}.params.pt'.format(model_name),\n",
        "    f_optimizer='{}.optimizer.pt'.format(model_name),\n",
        "    f_history='{}.history.json'.format(model_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsGdaUd-7gzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = IdiomClassifier(\n",
        "    module=model,\n",
        "    class_weights=class_weights,\n",
        "    print_report=False,\n",
        "     #\n",
        "    iterator_train=SkorchBucketIterator,\n",
        "    iterator_train__batch_size=args.batch_size,\n",
        "    iterator_train__sort_key=lambda x: len(x.sentence),\n",
        "    iterator_train__shuffle=True,\n",
        "    iterator_train__device=DEVICE,\n",
        "    iterator_train__one_hot=args.output_activation == 'softmax',\n",
        "     #\n",
        "    iterator_valid=SkorchBucketIterator,\n",
        "    iterator_valid__batch_size=args.eval_batch_size,\n",
        "    iterator_valid__sort_key=lambda x: len(x.sentence),\n",
        "    iterator_valid__shuffle=True,\n",
        "    iterator_valid__device=DEVICE,\n",
        "    iterator_valid__one_hot=args.output_activation == 'softmax',\n",
        "\n",
        "    train_split=predefined_split(SentenceDataset(data=(x_val, y_val))),\n",
        "    optimizer=torch.optim.Adam,\n",
        "    criterion=nn.BCELoss,\n",
        "    callbacks=[progress_bar, scorer, early_stopping, checkpoint],\n",
        "    device=DEVICE,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgUU4f0V7gwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "41d9dc4e-3d1e-46c4-8605-93d658ed6e3f"
      },
      "source": [
        "net.fit(SentenceDataset(data=(x_train, y_train)), y=None, epochs=args.max_epochs)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  epoch      F1    train_loss    valid_loss    cp       dur\n",
            "-------  ------  ------------  ------------  ----  --------\n",
            "      1  \u001b[36m0.1955\u001b[0m        \u001b[32m0.1770\u001b[0m        \u001b[35m0.0804\u001b[0m     +  186.4383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      2  \u001b[36m0.2113\u001b[0m        \u001b[32m0.1417\u001b[0m        0.0836     +  186.3342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      3  0.1561        \u001b[32m0.1379\u001b[0m        0.0887        186.1460\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      4  0.1812        \u001b[32m0.1361\u001b[0m        \u001b[35m0.0760\u001b[0m        186.0426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      5  0.2055        \u001b[32m0.1311\u001b[0m        \u001b[35m0.0736\u001b[0m        185.9689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      6  0.1873        0.1319        0.0769        185.9304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      7  0.2112        0.1324        0.0751        186.1491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      8  0.1652        0.1322        0.0880        185.9924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      9  0.2061        \u001b[32m0.1280\u001b[0m        \u001b[35m0.0719\u001b[0m        185.9795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     10  \u001b[36m0.2118\u001b[0m        0.1291        0.0822     +  185.9383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     11  0.1913        0.1303        0.0724        186.0105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     12  0.1936        \u001b[32m0.1261\u001b[0m        0.0789        186.3218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     13  0.2039        \u001b[32m0.1254\u001b[0m        0.0728        186.0217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     14  0.2086        \u001b[32m0.1252\u001b[0m        \u001b[35m0.0709\u001b[0m        186.2205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     15  \u001b[36m0.2579\u001b[0m        0.1256        \u001b[35m0.0707\u001b[0m     +  185.9465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     16  0.2053        0.1289        0.0726        186.0119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     17  0.2024        \u001b[32m0.1237\u001b[0m        0.0746        186.0199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     18  0.2150        0.1277        0.0730        185.9132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     19  0.2160        0.1256        0.0728        185.9559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     20  0.2389        0.1237        \u001b[35m0.0684\u001b[0m        186.2062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     21  0.2305        0.1297        0.0720        185.9301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     22  0.2061        0.1258        0.0763        186.1314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     23  0.2011        0.1299        0.0742        186.2796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     24  0.1943        0.1240        0.0772        186.2226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     25  0.1797        0.1270        0.0760        186.3130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     26  0.1986        0.1286        0.0748        186.2145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     27  0.2092        0.1271        0.0709        186.1995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     28  0.1854        0.1273        0.0748        185.9147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     29  0.1780        0.1285        0.0712        186.0236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     30  0.1886        0.1313        0.0737        186.2355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     31  0.2000        0.1246        0.0738        185.9878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     32  0.2052        \u001b[32m0.1219\u001b[0m        0.0709        186.0685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     33  0.2016        0.1230        0.0767        186.1481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "     34  0.1921        0.1280        0.0747        186.2509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping since F1 has not improved in the last 20 epochs.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrthjRiPLUL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bffa4c8-b067-4735-ff61-d3945d315dac"
      },
      "source": [
        "net.initialize()\n",
        "net.load_params(checkpoint=checkpoint)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Re-initializing optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxkiOcTagyDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fffd3a68-4d15-4008-b4fd-af53f7f77a48"
      },
      "source": [
        "print(model_name)\n",
        "args.eval = True\n",
        "if args.eval:\n",
        "    for code in LANGUAGE_CODES:\n",
        "        print('#' * 20)\n",
        "        print('# Evaluating Language: {}'.format(code))\n",
        "        print('#' * 20)\n",
        "        test_iterator = SkorchBucketIterator(\n",
        "            dataset=SentenceDataset(data=(x_dev[code], y_dev[code])),\n",
        "            batch_size=args.eval_batch_size,\n",
        "            sort=False,\n",
        "            sort_key=lambda x: len(x.sentence),\n",
        "            shuffle=False,\n",
        "            train=False,\n",
        "            one_hot=args.output_activation == 'softmax',\n",
        "            device=DEVICE)\n",
        "        args.dev_file = '/content/gdrive/My Drive/mwe_sharedtask/data/{}/dev.cupt'.format(code)\n",
        "        evaluate_model(net, test_iterator, tokenizer, args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distilbert-base-multilingual-cased.f1.128filters.[1, 2, 3, 4, 5]kernels.5poolstride.1layers.50lstm.0.2dropout.0.1init.sigmoidactivation.32batch.100epochs\n",
            "####################\n",
            "# Evaluating Language: DE\n",
            "####################\n",
            "0\n",
            "## Global evaluation\n",
            "* MWE-based: P=170/1055=0.1611 R=170/267=0.6367 F=0.2572\n",
            "* Tok-based: P=517/11746=0.0440 R=517/517=1.0000 F=0.0843\n",
            "\n",
            "## Per-category evaluation (partition of Global)\n",
            "* IRV: MWE-proportion: gold=14/267=5% pred=11/1055=1%\n",
            "* IRV: MWE-based: P=8/11=0.7273 R=8/14=0.5714 F=0.6400\n",
            "* IRV: Tok-based: P=22/26=0.8462 R=22/30=0.7333 F=0.7857\n",
            "* LVC.cause: MWE-proportion: gold=2/267=1% pred=2/1055=0%\n",
            "* LVC.cause: MWE-based: P=2/2=1.0000 R=2/2=1.0000 F=1.0000\n",
            "* LVC.cause: Tok-based: P=6/6=1.0000 R=6/6=1.0000 F=1.0000\n",
            "* LVC.full: MWE-proportion: gold=26/267=10% pred=18/1055=2%\n",
            "* LVC.full: MWE-based: P=18/18=1.0000 R=18/26=0.6923 F=0.8182\n",
            "* LVC.full: Tok-based: P=42/42=1.0000 R=42/63=0.6667 F=0.8000\n",
            "* <unlabeled>: MWE-proportion: gold=0/267=0% pred=846/1055=80%\n",
            "* <unlabeled>: MWE-based: P=0/846=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* <unlabeled>: Tok-based: P=0/11253=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* VID: MWE-proportion: gold=95/267=36% pred=77/1055=7%\n",
            "* VID: MWE-based: P=59/77=0.7662 R=59/95=0.6211 F=0.6860\n",
            "* VID: Tok-based: P=189/231=0.8182 R=189/236=0.8008 F=0.8094\n",
            "* VPC.full: MWE-proportion: gold=122/267=46% pred=94/1055=9%\n",
            "* VPC.full: MWE-based: P=77/94=0.8191 R=77/122=0.6311 F=0.7130\n",
            "* VPC.full: Tok-based: P=135/176=0.7670 R=135/170=0.7941 F=0.7803\n",
            "* VPC.semi: MWE-proportion: gold=8/267=3% pred=7/1055=1%\n",
            "* VPC.semi: MWE-based: P=6/7=0.8571 R=6/8=0.7500 F=0.8000\n",
            "* VPC.semi: Tok-based: P=11/12=0.9167 R=11/12=0.9167 F=0.9167\n",
            "\n",
            "## MWE continuity (partition of Global)\n",
            "* Continuous: MWE-proportion: gold=152/267=57% pred=441/1055=42%\n",
            "* Continuous: MWE-based: P=98/441=0.2222 R=98/152=0.6447 F=0.3305\n",
            "* Discontinuous: MWE-proportion: gold=115/267=43% pred=614/1055=58%\n",
            "* Discontinuous: MWE-based: P=72/614=0.1173 R=72/115=0.6261 F=0.1975\n",
            "\n",
            "## Number of tokens (partition of Global)\n",
            "* Multi-token: MWE-proportion: gold=187/267=70% pred=933/1055=88%\n",
            "* Multi-token: MWE-based: P=117/933=0.1254 R=117/187=0.6257 F=0.2089\n",
            "* Single-token: MWE-proportion: gold=80/267=30% pred=122/1055=12%\n",
            "* Single-token: MWE-based: P=53/122=0.4344 R=53/80=0.6625 F=0.5248\n",
            "\n",
            "## Whether seen in train (partition of Global)\n",
            "* Seen-in-train: MWE-proportion: gold=167/267=63% pred=102/1055=10%\n",
            "* Seen-in-train: MWE-based: P=102/102=1.0000 R=102/167=0.6108 F=0.7584\n",
            "* Unseen-in-train: MWE-proportion: gold=100/267=37% pred=953/1055=90%\n",
            "* Unseen-in-train: MWE-based: P=68/953=0.0714 R=68/100=0.6800 F=0.1292\n",
            "\n",
            "## Whether identical to train (partition of Seen-in-train)\n",
            "* Variant-of-train: MWE-proportion: gold=100/167=60% pred=62/102=61%\n",
            "* Variant-of-train: MWE-based: P=62/62=1.0000 R=62/100=0.6200 F=0.7654\n",
            "* Identical-to-train: MWE-proportion: gold=67/167=40% pred=40/102=39%\n",
            "* Identical-to-train: MWE-based: P=40/40=1.0000 R=40/67=0.5970 F=0.7477\n",
            "\n",
            "####################\n",
            "# Evaluating Language: GA\n",
            "####################\n",
            "0\n",
            "## Global evaluation\n",
            "* MWE-based: P=52/602=0.0864 R=52/126=0.4127 F=0.1429\n",
            "* Tok-based: P=287/7024=0.0409 R=287/287=1.0000 F=0.0785\n",
            "\n",
            "## Per-category evaluation (partition of Global)\n",
            "* IAV: MWE-proportion: gold=42/126=33% pred=25/602=4%\n",
            "* IAV: MWE-based: P=16/25=0.6400 R=16/42=0.3810 F=0.4776\n",
            "* IAV: Tok-based: P=51/110=0.4636 R=51/86=0.5930 F=0.5204\n",
            "* LVC.cause: MWE-proportion: gold=22/126=17% pred=16/602=3%\n",
            "* LVC.cause: MWE-based: P=10/16=0.6250 R=10/22=0.4545 F=0.5263\n",
            "* LVC.cause: Tok-based: P=35/54=0.6481 R=35/49=0.7143 F=0.6796\n",
            "* LVC.full: MWE-proportion: gold=29/126=23% pred=17/602=3%\n",
            "* LVC.full: MWE-based: P=11/17=0.6471 R=11/29=0.3793 F=0.4783\n",
            "* LVC.full: Tok-based: P=36/94=0.3830 R=36/65=0.5538 F=0.4528\n",
            "* <unlabeled>: MWE-proportion: gold=0/126=0% pred=522/602=87%\n",
            "* <unlabeled>: MWE-based: P=0/522=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* <unlabeled>: Tok-based: P=0/6674=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* VID: MWE-proportion: gold=22/126=17% pred=12/602=2%\n",
            "* VID: MWE-based: P=8/12=0.6667 R=8/22=0.3636 F=0.4706\n",
            "* VID: Tok-based: P=35/48=0.7292 R=35/65=0.5385 F=0.6195\n",
            "* VPC.full: MWE-proportion: gold=6/126=5% pred=5/602=1%\n",
            "* VPC.full: MWE-based: P=4/5=0.8000 R=4/6=0.6667 F=0.7273\n",
            "* VPC.full: Tok-based: P=10/14=0.7143 R=10/12=0.8333 F=0.7692\n",
            "* VPC.semi: MWE-proportion: gold=5/126=4% pred=5/602=1%\n",
            "* VPC.semi: MWE-based: P=3/5=0.6000 R=3/5=0.6000 F=0.6000\n",
            "* VPC.semi: Tok-based: P=10/30=0.3333 R=10/10=1.0000 F=0.5000\n",
            "\n",
            "## MWE continuity (partition of Global)\n",
            "* Continuous: MWE-proportion: gold=59/126=47% pred=208/602=35%\n",
            "* Continuous: MWE-based: P=30/208=0.1442 R=30/59=0.5085 F=0.2247\n",
            "* Discontinuous: MWE-proportion: gold=67/126=53% pred=394/602=65%\n",
            "* Discontinuous: MWE-based: P=22/394=0.0558 R=22/67=0.3284 F=0.0954\n",
            "\n",
            "## Number of tokens (partition of Global)\n",
            "* Multi-token: MWE-proportion: gold=126/126=100% pred=580/602=96%\n",
            "* Multi-token: MWE-based: P=52/580=0.0897 R=52/126=0.4127 F=0.1473\n",
            "* Single-token: MWE-proportion: gold=0/126=0% pred=22/602=4%\n",
            "* Single-token: MWE-based: P=0/22=0.0000 R=0/0=0.0000 F=0.0000\n",
            "\n",
            "## Whether seen in train (partition of Global)\n",
            "* Seen-in-train: MWE-proportion: gold=26/126=21% pred=10/602=2%\n",
            "* Seen-in-train: MWE-based: P=10/10=1.0000 R=10/26=0.3846 F=0.5556\n",
            "* Unseen-in-train: MWE-proportion: gold=100/126=79% pred=592/602=98%\n",
            "* Unseen-in-train: MWE-based: P=42/592=0.0709 R=42/100=0.4200 F=0.1214\n",
            "\n",
            "## Whether identical to train (partition of Seen-in-train)\n",
            "* Variant-of-train: MWE-proportion: gold=21/26=81% pred=5/10=50%\n",
            "* Variant-of-train: MWE-based: P=5/5=1.0000 R=5/21=0.2381 F=0.3846\n",
            "* Identical-to-train: MWE-proportion: gold=5/26=19% pred=5/10=50%\n",
            "* Identical-to-train: MWE-based: P=5/5=1.0000 R=5/5=1.0000 F=1.0000\n",
            "\n",
            "####################\n",
            "# Evaluating Language: HI\n",
            "####################\n",
            "0\n",
            "## Global evaluation\n",
            "* MWE-based: P=61/603=0.1012 R=61/186=0.3280 F=0.1546\n",
            "* Tok-based: P=413/6284=0.0657 R=413/413=1.0000 F=0.1233\n",
            "\n",
            "## Per-category evaluation (partition of Global)\n",
            "* LVC.full: MWE-proportion: gold=126/186=68% pred=43/603=7%\n",
            "* LVC.full: MWE-based: P=36/43=0.8372 R=36/126=0.2857 F=0.4260\n",
            "* LVC.full: Tok-based: P=90/121=0.7438 R=90/272=0.3309 F=0.4580\n",
            "* MVC: MWE-proportion: gold=49/186=26% pred=22/603=4%\n",
            "* MVC: MWE-based: P=21/22=0.9545 R=21/49=0.4286 F=0.5915\n",
            "* MVC: Tok-based: P=44/45=0.9778 R=44/98=0.4490 F=0.6154\n",
            "* <unlabeled>: MWE-proportion: gold=0/186=0% pred=532/603=88%\n",
            "* <unlabeled>: MWE-based: P=0/532=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* <unlabeled>: Tok-based: P=0/6082=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* VID: MWE-proportion: gold=11/186=6% pred=6/603=1%\n",
            "* VID: MWE-based: P=4/6=0.6667 R=4/11=0.3636 F=0.4706\n",
            "* VID: Tok-based: P=22/36=0.6111 R=22/43=0.5116 F=0.5570\n",
            "\n",
            "## MWE continuity (partition of Global)\n",
            "* Continuous: MWE-proportion: gold=171/186=92% pred=160/603=27%\n",
            "* Continuous: MWE-based: P=57/160=0.3563 R=57/171=0.3333 F=0.3444\n",
            "* Discontinuous: MWE-proportion: gold=15/186=8% pred=443/603=73%\n",
            "* Discontinuous: MWE-based: P=4/443=0.0090 R=4/15=0.2667 F=0.0175\n",
            "\n",
            "## Number of tokens (partition of Global)\n",
            "* Multi-token: MWE-proportion: gold=186/186=100% pred=592/603=98%\n",
            "* Multi-token: MWE-based: P=61/592=0.1030 R=61/186=0.3280 F=0.1568\n",
            "* Single-token: MWE-proportion: gold=0/186=0% pred=11/603=2%\n",
            "* Single-token: MWE-based: P=0/11=0.0000 R=0/0=0.0000 F=0.0000\n",
            "\n",
            "## Whether seen in train (partition of Global)\n",
            "* Seen-in-train: MWE-proportion: gold=86/186=46% pred=26/603=4%\n",
            "* Seen-in-train: MWE-based: P=26/26=1.0000 R=26/86=0.3023 F=0.4643\n",
            "* Unseen-in-train: MWE-proportion: gold=100/186=54% pred=577/603=96%\n",
            "* Unseen-in-train: MWE-based: P=35/577=0.0607 R=35/100=0.3500 F=0.1034\n",
            "\n",
            "## Whether identical to train (partition of Seen-in-train)\n",
            "* Variant-of-train: MWE-proportion: gold=45/86=52% pred=11/26=42%\n",
            "* Variant-of-train: MWE-based: P=11/11=1.0000 R=11/45=0.2444 F=0.3929\n",
            "* Identical-to-train: MWE-proportion: gold=41/86=48% pred=15/26=58%\n",
            "* Identical-to-train: MWE-based: P=15/15=1.0000 R=15/41=0.3659 F=0.5357\n",
            "\n",
            "####################\n",
            "# Evaluating Language: PT\n",
            "####################\n",
            "0\n",
            "## Global evaluation\n",
            "* MWE-based: P=139/3407=0.0408 R=139/397=0.3501 F=0.0731\n",
            "* Tok-based: P=885/40855=0.0217 R=885/885=1.0000 F=0.0424\n",
            "\n",
            "## Per-category evaluation (partition of Global)\n",
            "* IRV: MWE-proportion: gold=73/397=18% pred=39/3407=1%\n",
            "* IRV: MWE-based: P=20/39=0.5128 R=20/73=0.2740 F=0.3571\n",
            "* IRV: Tok-based: P=79/163=0.4847 R=79/147=0.5374 F=0.5097\n",
            "* LVC.cause: MWE-proportion: gold=6/397=2% pred=4/3407=0%\n",
            "* LVC.cause: MWE-based: P=4/4=1.0000 R=4/6=0.6667 F=0.8000\n",
            "* LVC.cause: Tok-based: P=9/9=1.0000 R=9/13=0.6923 F=0.8182\n",
            "* LVC.full: MWE-proportion: gold=236/397=59% pred=148/3407=4%\n",
            "* LVC.full: MWE-based: P=88/148=0.5946 R=88/236=0.3729 F=0.4583\n",
            "* LVC.full: Tok-based: P=303/532=0.5695 R=303/480=0.6312 F=0.5988\n",
            "* MVC: MWE-proportion: gold=2/397=1% pred=2/3407=0%\n",
            "* MVC: MWE-based: P=0/2=0.0000 R=0/2=0.0000 F=0.0000\n",
            "* MVC: Tok-based: P=4/16=0.2500 R=4/4=1.0000 F=0.4000\n",
            "* <unlabeled>: MWE-proportion: gold=0/397=0% pred=3170/3407=93%\n",
            "* <unlabeled>: MWE-based: P=0/3170=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* <unlabeled>: Tok-based: P=0/39944=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* VID: MWE-proportion: gold=80/397=20% pred=44/3407=1%\n",
            "* VID: MWE-based: P=27/44=0.6136 R=27/80=0.3375 F=0.4355\n",
            "* VID: Tok-based: P=136/191=0.7120 R=136/241=0.5643 F=0.6296\n",
            "\n",
            "## MWE continuity (partition of Global)\n",
            "* Continuous: MWE-proportion: gold=231/397=58% pred=1368/3407=40%\n",
            "* Continuous: MWE-based: P=81/1368=0.0592 R=81/231=0.3506 F=0.1013\n",
            "* Discontinuous: MWE-proportion: gold=166/397=42% pred=2039/3407=60%\n",
            "* Discontinuous: MWE-based: P=58/2039=0.0284 R=58/166=0.3494 F=0.0526\n",
            "\n",
            "## Number of tokens (partition of Global)\n",
            "* Multi-token: MWE-proportion: gold=397/397=100% pred=3177/3407=93%\n",
            "* Multi-token: MWE-based: P=139/3177=0.0438 R=139/397=0.3501 F=0.0778\n",
            "* Single-token: MWE-proportion: gold=0/397=0% pred=230/3407=7%\n",
            "* Single-token: MWE-based: P=0/230=0.0000 R=0/0=0.0000 F=0.0000\n",
            "\n",
            "## Whether seen in train (partition of Global)\n",
            "* Seen-in-train: MWE-proportion: gold=297/397=75% pred=97/3407=3%\n",
            "* Seen-in-train: MWE-based: P=96/97=0.9897 R=96/297=0.3232 F=0.4873\n",
            "* Unseen-in-train: MWE-proportion: gold=100/397=25% pred=3310/3407=97%\n",
            "* Unseen-in-train: MWE-based: P=43/3310=0.0130 R=43/100=0.4300 F=0.0252\n",
            "\n",
            "## Whether identical to train (partition of Seen-in-train)\n",
            "* Variant-of-train: MWE-proportion: gold=174/297=59% pred=62/97=64%\n",
            "* Variant-of-train: MWE-based: P=62/62=1.0000 R=62/174=0.3563 F=0.5254\n",
            "* Identical-to-train: MWE-proportion: gold=123/297=41% pred=35/97=36%\n",
            "* Identical-to-train: MWE-based: P=34/35=0.9714 R=34/123=0.2764 F=0.4304\n",
            "\n",
            "####################\n",
            "# Evaluating Language: ZH\n",
            "####################\n",
            "0\n",
            "## Global evaluation\n",
            "* MWE-based: P=160/1777=0.0900 R=160/265=0.6038 F=0.1567\n",
            "* Tok-based: P=417/18263=0.0228 R=417/417=1.0000 F=0.0446\n",
            "\n",
            "## Per-category evaluation (partition of Global)\n",
            "* LVC.cause: MWE-proportion: gold=6/265=2% pred=6/1777=0%\n",
            "* LVC.cause: MWE-based: P=5/6=0.8333 R=5/6=0.8333 F=0.8333\n",
            "* LVC.cause: Tok-based: P=12/13=0.9231 R=12/12=1.0000 F=0.9600\n",
            "* LVC.full: MWE-proportion: gold=33/265=12% pred=23/1777=1%\n",
            "* LVC.full: MWE-based: P=19/23=0.8261 R=19/33=0.5758 F=0.6786\n",
            "* LVC.full: Tok-based: P=46/54=0.8519 R=46/67=0.6866 F=0.7603\n",
            "* MVC: MWE-proportion: gold=100/265=38% pred=71/1777=4%\n",
            "* MVC: MWE-based: P=61/71=0.8592 R=61/100=0.6100 F=0.7135\n",
            "* MVC: Tok-based: P=119/139=0.8561 R=119/168=0.7083 F=0.7752\n",
            "* <unlabeled>: MWE-proportion: gold=0/265=0% pred=1584/1777=89%\n",
            "* <unlabeled>: MWE-based: P=0/1584=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* <unlabeled>: Tok-based: P=0/17874=0.0000 R=0/0=0.0000 F=0.0000\n",
            "* VID: MWE-proportion: gold=18/265=7% pred=13/1777=1%\n",
            "* VID: MWE-based: P=11/13=0.8462 R=11/18=0.6111 F=0.7097\n",
            "* VID: Tok-based: P=17/27=0.6296 R=17/22=0.7727 F=0.6939\n",
            "* VPC.semi: MWE-proportion: gold=108/265=41% pred=80/1777=5%\n",
            "* VPC.semi: MWE-based: P=64/80=0.8000 R=64/108=0.5926 F=0.6809\n",
            "* VPC.semi: Tok-based: P=109/156=0.6987 R=109/148=0.7365 F=0.7171\n",
            "\n",
            "## MWE continuity (partition of Global)\n",
            "* Continuous: MWE-proportion: gold=232/265=88% pred=1054/1777=59%\n",
            "* Continuous: MWE-based: P=138/1054=0.1309 R=138/232=0.5948 F=0.2146\n",
            "* Discontinuous: MWE-proportion: gold=33/265=12% pred=723/1777=41%\n",
            "* Discontinuous: MWE-based: P=22/723=0.0304 R=22/33=0.6667 F=0.0582\n",
            "\n",
            "## Number of tokens (partition of Global)\n",
            "* Multi-token: MWE-proportion: gold=147/265=55% pred=1627/1777=92%\n",
            "* Multi-token: MWE-based: P=88/1627=0.0541 R=88/147=0.5986 F=0.0992\n",
            "* Single-token: MWE-proportion: gold=118/265=45% pred=150/1777=8%\n",
            "* Single-token: MWE-based: P=72/150=0.4800 R=72/118=0.6102 F=0.5373\n",
            "\n",
            "## Whether seen in train (partition of Global)\n",
            "* Seen-in-train: MWE-proportion: gold=152/265=57% pred=92/1777=5%\n",
            "* Seen-in-train: MWE-based: P=91/92=0.9891 R=91/152=0.5987 F=0.7459\n",
            "* Unseen-in-train: MWE-proportion: gold=113/265=43% pred=1685/1777=95%\n",
            "* Unseen-in-train: MWE-based: P=69/1685=0.0409 R=69/113=0.6106 F=0.0768\n",
            "\n",
            "## Whether identical to train (partition of Seen-in-train)\n",
            "* Variant-of-train: MWE-proportion: gold=7/152=5% pred=5/92=5%\n",
            "* Variant-of-train: MWE-based: P=5/5=1.0000 R=5/7=0.7143 F=0.8333\n",
            "* Identical-to-train: MWE-proportion: gold=145/152=95% pred=87/92=95%\n",
            "* Identical-to-train: MWE-based: P=86/87=0.9885 R=86/145=0.5931 F=0.7414\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jX5Yc2I9rhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7b262882-e544-4e87-a9e8-cfbf4ccce6a4"
      },
      "source": [
        "print(\"#\" * 20)\n",
        "print(\"\\nTraining finished!!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "\n",
            "Training finished!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooo8cvHGjvAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}