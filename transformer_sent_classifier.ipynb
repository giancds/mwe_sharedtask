{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 52566,\n",
      "  \"iopub_port\": 52567,\n",
      "  \"stdin_port\": 52568,\n",
      "  \"control_port\": 52570,\n",
      "  \"hb_port\": 52569,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"e610fee3-354b090fdd670f29db3b9d49\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-48648ad9-bee6-4098-b805-43c171777f8a.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible models\n",
    "\n",
    "`bert-base-multilingual-cased`: (New, recommended) 12-layer, 768-hidden, 12-heads, 110M parameters. Trained on cased text in the top 104 languages with the largest Wikipedias\n",
    "\n",
    "`xlm-mlm-100-1280`: 16-layer, 1280-hidden, 16-heads XLM model trained with MLM (Masked Language Modeling) on 100 languages.\n",
    "\n",
    "`distilbert-base-multilingual-cased`: 6-layer, 768-hidden, 12-heads, 134M parameters The multilingual DistilBERT model distilled from the Multilingual BERT model bert-base-multilingual-cased checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from numpy.ma import MaskedArray\n",
    "import sklearn.utils.fixes\n",
    "\n",
    "sklearn.utils.fixes.MaskedArray = MaskedArray\n",
    "\n",
    "import skopt\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BASE_DIR = os.path.expanduser(\"~\")     # this will point to the user's home\n",
    "TRAIN_DIR = BASE_DIR +  \"/ray_results\"\n",
    "\n",
    "\n",
    "model_type = 'avg.distilbert-base-multilingual-cased'\n",
    "# model_type = 'bert-base-multilingual-cased'\n",
    "with open('data/{}.embdata.pkl'.format(model_type), 'rb') as f:\n",
    "    data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66338, 768) (66338,)\n",
      "(4330, 768) (4330,)\n"
     ]
    }
   ],
   "source": [
    "codes = ['DE', 'GA', 'HI', 'PT', 'ZH']\n",
    "\n",
    "\n",
    "x_train = np.concatenate([data[code]['x_train'] for code in codes], axis=0)\n",
    "y_train = np.concatenate([data[code]['y_train'] for code in codes], axis=0)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "x_dev = np.concatenate([data[code]['x_dev'] for code in codes], axis=0)\n",
    "y_dev = np.concatenate([data[code]['y_dev'] for code in codes], axis=0)\n",
    "print(x_dev.shape, y_dev.shape)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn_space = {\n",
    "#     'model': [KNeighborsClassifier(n_jobs=-1)],\n",
    "    'n_neighbors': Integer(1, 10),\n",
    "    'weights':  Categorical(['uniform', 'distance']),\n",
    "    'p':  Integer(1, 2),\n",
    "    'n_jobs': Categorical([-1])\n",
    "}\n",
    "\n",
    "l1svm_space = {\n",
    "#     'model': [LinearSVC(dual=False, class_weight='balanced', random_state=SEED)],\n",
    "    'penalty': Categorical(['l1']),\n",
    "    'loss':  Categorical(['squared_hinge']),\n",
    "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "    'dual': Categorical([False]),\n",
    "    'class_weight': Categorical(['balanced']),\n",
    "    'random_state': Categorical([SEED])\n",
    "}\n",
    "\n",
    "l2svm_space = {\n",
    "#     'model': [LinearSVC(dual=True, class_weight='balanced', random_state=SEED)],\n",
    "    'penalty': Categorical(['l2']),\n",
    "    'loss':  Categorical(['hinge', 'squared_hinge']),\n",
    "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "    'dual': Categorical([True]),\n",
    "    'class_weight': Categorical(['balanced']),\n",
    "    'random_state': Categorical([SEED])\n",
    "}\n",
    "\n",
    "\n",
    "svm_space = {\n",
    "#     'model': [SVC(class_weight='balanced', random_state=SEED)],\n",
    "    'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'degree': Integer(1, 3),\n",
    "    'gamma': Categorical(['scale', 'auto']),\n",
    "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "    'class_weight': Categorical(['balanced']),\n",
    "    'random_state': Categorical([SEED])\n",
    "}\n",
    "\n",
    "lreg_space = {\n",
    "#     'model': [LogisticRegression(solver='liblinear')],\n",
    "    'penalty': Categorical(['l1', 'l2']),\n",
    "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "    'solver': Categorical(['liblinear'])\n",
    "}\n",
    "\n",
    "adab_space = {\n",
    "#     'model': [AdaBoostClassifier(\n",
    "#         DecisionTreeClassifier(max_depth=Integer(1, 10)),\n",
    "#         random_state=SEED)],\n",
    "    'n_estimators': Integer(5, 50) ,\n",
    "    'learning_rate': Real(0.1, 1.0, prior='uniform'),\n",
    "    'random_state': Categorical([SEED])\n",
    "}\n",
    "\n",
    "hist_space = {\n",
    "#     'model': [HistGradientBoostingClassifier(random_state=SEED)],\n",
    "    'learning_rate': Real(0.1, 1.0, prior='uniform'),\n",
    "    'max_leaf_nodes': Integer(2, 100),\n",
    "    'max_depth': Integer(2, 100),\n",
    "    'min_samples_leaf': Integer(1, 50),\n",
    "    'l2_regularization': Real(0.0, 10.0, prior='uniform'),\n",
    "    'max_bins': Integer(5, 300),\n",
    "    'random_state': Categorical([SEED])\n",
    "}\n",
    "\n",
    "rf_space = {\n",
    "#     'model': [RandomForestClassifier(random_state=SEED, n_jobs=-1)],\n",
    "    'n_estimators': Integer(5, 500),\n",
    "    'criterion': Categorical(['gini', 'entropy']),\n",
    "    'max_leaf_nodes': Integer(2, 100),\n",
    "    'max_depth': Integer(2, 100),\n",
    "    'min_samples_leaf': Integer(1, 50),\n",
    "    'min_samples_split': Integer(1, 10),\n",
    "    'max_features': Categorical(['auto', 'sqrt', 'log2', None]),\n",
    "    'l2_regularization': Real(0.0, 10.0, prior='uniform'),\n",
    "    'random_state': Categorical([SEED]),\n",
    "    'n_jobs': Categorical([-1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed: 31.9min finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:67: FutureWarning: Class MaskedArray is deprecated; MaskedArray is deprecated in version 0.23 and will be removed in version 0.25. Use numpy.ma.MaskedArray instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes exactly one argument (the instance to initialize)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-661f0661dec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val. score: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 optim_result = self._step(\n\u001b[1;32m    679\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m                     \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m                 )\n\u001b[1;32m    682\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;31m# `\"param_%s\" % name` at the first occurence of `name`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;31m# Setting the value at an index also unmasks that index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                 \u001b[0mparam_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"param_%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcand_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes exactly one argument (the instance to initialize)"
     ]
    }
   ],
   "source": [
    "opt = skopt.BayesSearchCV(\n",
    "    KNeighborsClassifier(n_jobs=-1),\n",
    "    knn_space,   \n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")\n",
    "opt.fit(x_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))\n",
    "\n",
    "y_pred = opt.predict(x_dev)\n",
    "\n",
    "print(confusion_matrix(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "    LinearSVC(dual=False, class_weight='balanced', random_state=SEED),\n",
    "    l1svm_space,   \n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")\n",
    "opt.fit(x_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))\n",
    "\n",
    "y_pred = opt.predict(x_dev)\n",
    "\n",
    "print(confusion_matrix(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "    LinearSVC(dual=True, class_weight='balanced', random_state=SEED),\n",
    "    l2svm_space,   \n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")\n",
    "opt.fit(x_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))\n",
    "\n",
    "y_pred = opt.predict(x_dev)\n",
    "\n",
    "print(confusion_matrix(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "    SVC(class_weight='balanced', random_state=SEED),\n",
    "    svm_space,   \n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")\n",
    "opt.fit(x_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))\n",
    "\n",
    "y_pred = opt.predict(x_dev)\n",
    "\n",
    "print(confusion_matrix(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "    LogisticRegression(solver='liblinear'),\n",
    "    lreg_space,   \n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")\n",
    "opt.fit(x_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))\n",
    "\n",
    "y_pred = opt.predict(x_dev)\n",
    "\n",
    "print(confusion_matrix(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "    KNeighborsClassifier(n_jobs=-1),\n",
    "    knn_space,   \n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")\n",
    "opt.fit(x_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))\n",
    "\n",
    "y_pred = opt.predict(x_dev)\n",
    "\n",
    "print(confusion_matrix(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "    AdaBoostClassifier(),\n",
    "    adab_space,   \n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")\n",
    "opt.fit(x_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))\n",
    "\n",
    "y_pred = opt.predict(x_dev)\n",
    "\n",
    "print(confusion_matrix(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "    HistGradientBoostingClassifier(random_state=SEED),\n",
    "    hist_space,   \n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")\n",
    "opt.fit(x_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))\n",
    "\n",
    "y_pred = opt.predict(x_dev)\n",
    "\n",
    "print(confusion_matrix(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "    RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "    rf_space,   \n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")\n",
    "opt.fit(x_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))\n",
    "\n",
    "y_pred = opt.predict(x_dev)\n",
    "\n",
    "print(confusion_matrix(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
