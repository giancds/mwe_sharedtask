{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible models\n",
    "\n",
    "`bert-base-multilingual-cased`: (New, recommended) 12-layer, 768-hidden, 12-heads, 110M parameters. Trained on cased text in the top 104 languages with the largest Wikipedias\n",
    "\n",
    "`xlm-mlm-100-1280`: 16-layer, 1280-hidden, 16-heads XLM model trained with MLM (Masked Language Modeling) on 100 languages.\n",
    "\n",
    "`distilbert-base-multilingual-cased`: 6-layer, 768-hidden, 12-heads, 134M parameters The multilingual DistilBERT model distilled from the Multilingual BERT model bert-base-multilingual-cased checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BASE_DIR = os.path.expanduser(\"~\")     # this will point to the user's home\n",
    "TRAIN_DIR = BASE_DIR +  \"/ray_results\"\n",
    "\n",
    "\n",
    "model_type = 'distilbert-base-multilingual-cased'\n",
    "# model_type = 'bert-base-multilingual-cased'\n",
    "with open('/Users/gian/Documents/research/mwe_sharedtask/data/{}.embdata.pkl'.format(model_type), 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = ['DE', 'GA', 'HI', 'PT', 'ZH']\n",
    "\n",
    "\n",
    "x_train = np.concatenate([data[code]['x_train'] for code in codes], axis=0)\n",
    "y_train = np.concatenate([data[code]['y_train'] for code in codes], axis=0)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "x_dev = np.concatenate([data[code]['x_dev'] for code in codes], axis=0)\n",
    "y_dev = np.concatenate([data[code]['y_dev'] for code in codes], axis=0)\n",
    "print(x_dev.shape, y_dev.shape)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_space = {\n",
    "    'model': [KNeighborsClassifier(n_jobs=-1)],\n",
    "    'model__n_neighbors': Integer(1, 10),\n",
    "    'model__weights':  Categorical(['uniform', 'distance']),\n",
    "    'model__p':  Integer(1, 2)\n",
    "}\n",
    "\n",
    "lsvm_space = {\n",
    "    'model': [LinearSVC(dual=False, class_weight='balanced', random_state=SEED)],\n",
    "    'model__penalty': Categorical(['l1', 'l2']),\n",
    "    'model__loss':  Categorical(['hinge', 'squared_hinge']),\n",
    "    'model__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "}\n",
    "\n",
    "\n",
    "svm_space = {\n",
    "    'model': [SVC(class_weight='balanced', random_state=SEED)],\n",
    "    'model__kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "    'model__degree': Integer(1, 3),\n",
    "    'model__gamma': Categorical(['scale', 'auto']),\n",
    "    'model__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "}\n",
    "\n",
    "lreg_space = {\n",
    "    'model': [LogisticRegression(solver='liblinear')],\n",
    "    'model__penalty': Categorical(['l1', 'l2']),\n",
    "    'model__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "}\n",
    "\n",
    "adab_space = {\n",
    "    'model': [AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=Integer(1, 10)),\n",
    "        random_state=SEED)],\n",
    "    'model__n_estimators': Integer(5, 50) ,\n",
    "    'model__learning_rate': Real(0.1, 1.0, prior='uniform'),\n",
    "}\n",
    "\n",
    "hist_space = {\n",
    "    'model': [HistGradientBoostingClassifier(random_state=SEED)],\n",
    "    'model__learning_rate': Real(0.1, 1.0, prior='uniform'),\n",
    "    'model__max_leaf_nodes': Integer(2, 100),\n",
    "    'model__max_depth': Integer(2, 100),\n",
    "    'model__min_samples_leaf': Integer(1, 50),\n",
    "    'model__l2_regularization': Real(0.0, 10.0, prior='uniform'),\n",
    "    'model__max_bins': Integer(5, 300)\n",
    "}\n",
    "\n",
    "rf_space = {\n",
    "    'model': [RandomForestClassifier(random_state=SEED, n_jobs=-1)],\n",
    "    'model__n_estimators': Integer(5, 500),\n",
    "    'model__criterion': Categorical(['gini', 'entropy']),\n",
    "    'model__max_leaf_nodes': Integer(2, 100),\n",
    "    'model__max_depth': Integer(2, 100),\n",
    "    'model__min_samples_leaf': Integer(1, 50),\n",
    "    'model__min_samples_split': Integer(1, 10),\n",
    "    'model__max_features': Categorical(['auto', 'sqrt', 'log2', None]),\n",
    "    'model__l2_regularization': Real(0.0, 10.0, prior='uniform')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('model', LogisticRegression(solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "   pipe,[\n",
    "#        (knn_space, 20),\n",
    "#        (lsvm_space, 20),\n",
    "       (svm_space, 20),\n",
    "#        (lreg_space, 20),\n",
    "       (adab_space, 20),\n",
    "       (hist_space, 20),\n",
    "       (rf_space, 20),\n",
    "     ], # (parameter space, # of evaluations)\n",
    "    n_iter=32,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    scoring='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(x_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = opt.predict(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
